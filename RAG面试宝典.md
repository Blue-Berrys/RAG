# RAG 面试宝典

## C1: RAG 核心概念

### 什么是 RAG？
RAG (Retrieval-Augmented Generation) 是一种将**参数化知识**（LLM 内部权重）与**非参数化知识**（外部知识库）结合的技术范式。本质是让 LLM 学会"开卷考试"——在生成前先检索外部资料，提升准确性和时效性。

### 技术架构
**两阶段流程**：
1. **检索阶段**：嵌入模型将知识库向量化存入向量数据库，用户查询时通过相似度搜索召回相关文档
2. **生成阶段**：LLM 基于检索到的上下文和原始问题，遵循 Prompt 指令生成答案

### 技术演进
- **Naive RAG**：离线索引 + 在线检索→生成（基础线性流程）
- **Advanced RAG**：增加检索前（查询重写）和检索后（重排）优化
- **Modular RAG**：积木式可编排流程（动态路由、多路融合）

### RAG vs 微调
**选型路径**：提示工程 → RAG → 微调
- **RAG 适用**：缺乏特定/实时知识、需抑制幻觉、领域专业性不足
- **微调适用**：改变模型行为/风格/格式（如特定输出格式、对话风格）

### 核心优势
1. **准确可信**：补充专业盲区，抑制幻觉，可溯源性
2. **时效保障**：知识库独立更新，解决知识时滞
3. **成本效益**：避免高频微调，可用更小基础模型
4. **模块扩展**：支持多源集成，检索与生成解耦

---

## C2: 数据加载与分块

### 文本分块重要性
**两大限制**：
- **嵌入模型**：上下文窗口限制（如 bge-base-zh-v1.5 为 512 token）
- **LLM**：总上下文限制，影响容纳相关信息量

**为何不能过大**：
1. **嵌入信息损失**：长文本压缩到单一向量时语义稀释
2. **Lost in the Middle**：LLM 难以从长上下文中提取关键信息
3. **主题稀释**：混合多主题的块检索相关性低

### 核心分块策略
**1. 固定大小分块**
- 原理：按段落分割 + 智能合并
- 优势：简单快速、计算开销小
- 劣势：可能切断语义边界

**2. 递归字符分块**（推荐）
- 原理：分隔符层级递归（段落→句子→单词→字符）
- 优势：平衡语义完整性与大小控制
- 配置：`separators=["\n\n", "\n", "。", "。", " ", ""]`

**3. 语义分块**
- 原理：计算相邻句子语义距离，在显著变化处切分
- 断点识别：percentile（默认）、standard_deviation、interquartile、gradient
- 优势：高度内部语义一致性

**4. 结构化分块**
- Markdown 标题分块：保留元数据（标题路径），可与递归分块组合使用
- Unstructured：基于文档元素（Title/NarrativeText/ListItem）智能组合
- LlamaIndex：节点解析器体系，支持 SentenceWindow（句子+上下文窗口）

---

## C3: 索引与检索优化

### 向量数据库选择
- **大规模**：Milvus、Pinecone
- **轻量级**：FAISS、Chroma

### 检索优化策略
**1. 混合检索**
- 向量检索 + 关键词检索（BM25）
- RRF（Reciprocal Rank Fusion）融合排序

**2. 重排序**
- 对初步检索结果二次精选
- 提升最终传给 LLM 的上下文质量

**3. 父子文档检索**
- 小块精确检索 + 大块完整生成
- 平衡检索精确性与上下文完整性

**4. 递归检索**
- 文档树结构 → 先检索父节点再获取子节点
- 保持文档层级关系

---

## C4: 高级检索策略

### Text2SQL
- 将自然语言转换为结构化查询
- 应用场景：数据库问答、数据分析

### 元数据过滤
- 结合向量检索与结构化元数据过滤
- 提升检索精确性

### 多模态检索
- 支持图像、表格等多模态内容
- 扩展 RAG 能力边界

---

## C5: 格式化生成

### 为什么需要格式化输出？
- RAG 驱动应用需要结构化数据（如电商商品卡片）
- 自然语言转 API 调用
- 数据自动提取（新闻事件抽取）

### 实现方法

**1. Output Parsers**
- **PydanticOutputParser**：定义数据模型 → 生成格式指令 → 注入 Prompt → 解析验证
- **JsonOutputParser**：处理嵌套结构 JSON
- 工作流：定义 Schema → 引导生成 → 解析验证

**2. Function Calling（推荐）**
- 多轮对话流程：定义工具 → 用户提问 → 模型决策 → 代码执行 → 结果反馈 → 最终生成
- 优势：可靠性高、意图识别、支持外部世界交互
- 核心价值：构建 AI Agent 的基础

**3. 不依赖框架的方法**
- 明确要求 JSON 格式
- 提供 JSON Schema
- Few-shot 示例
- 语法约束（GBNF）

---

## C6: RAG 评估体系

### RAG 三元组（TruLens）
**1. 上下文相关性**（检索性能）
- 核心问题：检索到的内容是否与查询相关？
- 指标：Context Precision、Context Recall、F1、MRR、MAP

**2. 忠实度/可信度**（生成可靠性）
- 核心问题：答案是否基于上下文？
- 衡量 LLM 幻觉程度

**3. 答案相关性**（端到端表现）
- 核心问题：答案是否直接、完整回答问题？
- 用户最直观的感受

### 评估方法

**基于 LLM 的评估**（主流）
- 忠实度：分解答案为断言 → 逐个验证
- 答案相关性：分析对齐程度，惩罚答非所问

**基于词汇重叠**（快速筛选）
- **ROUGE**：召回率导向（"说全了没"）
- **BLEU**：精确率导向 + 长度惩罚（"说对了没"）
- **METEOR**：调和平均 + 同义词匹配

---

## C7: GraphRAG

### 传统 RAG 局限
- 关系理解缺失（难以捕捉实体间复杂关系）
- 上下文碎片化
- 推理能力有限（不支持多跳推理）
- 跨文档联结能力弱

### GraphRAG 核心优势
- **结构化语义表达**：图形式编码实体关系
- **增强推理能力**：支持多跳推理
- **事实性与可解释性**：可追溯推理路径
- **异构数据集成**：统一结构化与非结构化数据

### 架构三阶段
**1. 知识图谱构建**
- 知识抽取（实体、关系、属性）
- 质量控制（置信度评估、冲突消解）
- 图谱融合（实体对齐、去重）
- 存储：Neo4j、NebulaGraph 等

**2. 图谱检索**
- 实体定位 → 子图探索 → 结构化证据抽取
- 混合检索：图检索 + 文本检索

**3. 增强生成**
- 将图结构与原文片段联合提供
- 明确要求引用图证据

### 方法论分类
- **知识驱动型**：完全依赖图谱（高精度、高可解释）
- **索引驱动型**：图结构融入文本索引（低成本）
- **混合型**：图检索 + 文本检索重排融合（综合表现好）

---

## C8: 项目实战 - 尝尝咸淡系统

### 项目特点
- **数据**：HowToCook 菜谱（300+ Markdown 文件）
- **结构**：高度规整（必备原料、计算、操作、附加内容）
- **篇幅**：单个菜谱约 700 字

### 核心设计
**父子文档策略**
- **小块检索**：精确匹配用户需求（如"必备原料"章节）
- **大块生成**：保持上下文完整性（整个菜谱文档）
- **原理**：小块找得准，大块答得全

### 查询路由
- **list 查询**：推荐菜品 → 简洁输出
- **detail 查询**：制作方法 → 分步指导
- **general 查询**：一般信息 → 基础回答

### 混合检索
- 向量检索（语义）+ BM25（关键词）
- RRF 融合排序
- 去重与父文档获取

---

## C9: 图 RAG 高级架构

### 智能查询路由
**四个分析维度**：
1. **复杂度**：0.0-0.3 简单 / 0.4-0.7 中等 / 0.8-1.0 高复杂
2. **关系密集度**：单一实体 / 实体关系 / 复杂网络
3. **推理需求**：多跳推理？因果分析？对比分析？
4. **实体识别**：实体数量和类型

**路由策略**：
- 简单查询 → 传统混合检索
- 复杂推理 → 图 RAG 检索
- 中等复杂 → 组合检索

### 降级策略
- 图 RAG 失败 → 降级到传统混合检索
- 传统混合失败 → 系统异常
- 保证服务可用性

### 图数据处理流程
Neo4j 图数据 → 结构化文档构建 → 智能分块 → Milvus 向量索引

---

## 面试高频问题

### 1. RAG vs 长上下文？
- **RAG**：精准检索、成本低、可溯源
- **长上下文**：简单暴力、成本高、检索质量依赖模型
- **趋势**：两者结合（RAG 提供精准上下文，长上下文处理剩余信息）

### 2. 如何优化检索质量？
- 混合检索（向量 + BM25）
- 重排序（Rerank）
- 查询重写（Query Rewrite）
- 父子文档策略

### 3. 如何评估 RAG 系统？
- **检索评估**：上下文相关性、精确率、召回率、F1
- **生成评估**：忠实度、答案相关性
- **端到端**：用户满意度、响应时间

### 4. GraphRAG vs 传统 RAG？
- **GraphRAG**：擅长关系推理、多跳问答、事实溯源
- **传统 RAG**：擅长语义检索、简单问答
- **选择**：根据任务复杂度和数据特点选择

### 5. Function Calling 优势？
- 可靠性高（模型原生支持）
- 意图识别（自动选择工具）
- 外部交互（API、数据库、硬件控制）

### 6. 如何处理长文档？
- 递归分块（保持语义完整性）
- 父子文档（小块检索 + 大块生成）
- 递归检索（文档树结构）
- 摘要索引（文档 + 摘要混合检索）

---

## 技术选型建议

### 开发框架
- **LangChain**：生态丰富、快速集成
- **LlamaIndex**：数据索引强、节点解析器丰富
- **原生开发**：精细控制（AI 辅助下可行）

### 向量数据库
- **大规模生产**：Milvus、Pinecone
- **中小规模**：Chroma、FAISS
- **云原生**：Pinecone、Weaviate Cloud

### 评估工具
- **自动化评估**：RAGAS、TruLens
- **手工评估**：小规模测试集 + 人工打分
- **A/B 测试**：线上对比

### 嵌入模型
- **中文**：bge-small/large-zh-v1.5、m3e-base
- **英文**：text-embedding-ada-002、all-MiniLM-L6-v2
- **多语言**：bge-m3、multilingual-e5

---

## 实战经验

### 常见问题
1. **检索召回不足**：混合检索、查询重写、扩大 top_k
2. **幻觉严重**：重排序、提高温度参数、加强上下文相关性
3. **响应慢**：缓存、索引优化、流式输出
4. **成本高**：模型量化、缓存、小模型 + RAG

### 优化技巧
- **索引优化**：分层索引、元数据过滤
- **检索优化**：重排序、查询扩展
- **生成优化**：Prompt 工程、Few-shot、温度调整
- **系统优化**：缓存、批处理、异步处理

### 生产部署
- **监控**：检索质量、生成质量、系统性能
- **降级**：多级降级策略保证可用性
- **A/B 测试**：新策略上线前对比测试
- **日志**：完整日志便于问题定位

---

**总结**：RAG 是将 LLM 内部知识与外部知识库结合的技术范式，通过检索增强生成提升准确性、时效性和可信度。从 Naive RAG 到 Advanced RAG 再到 Modular RAG，技术不断演进。GraphRAG 等高级架构进一步增强了关系推理能力。构建高质量 RAG 系统需要关注数据分块、索引构建、检索优化、格式化生成和评估体系等各个环节。