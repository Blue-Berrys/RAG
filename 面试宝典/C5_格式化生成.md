# C5: 格式化生成

## 一、为什么需要格式化生成？

### 1.1 应用场景

从大语言模型（LLM）那里获得一段非结构化的文本在应用中常常不满足实际需求。为了实现更复杂的逻辑、与外部工具交互或以用户友好的方式展示数据，需要模型能够输出具有特定结构的数据。

**具体应用场景**：
- **RAG 驱动的电商客服**：返回包含产品名称、价格、特性、购买链接的 JSON 列表，便于前端渲染成商品卡片
- **自然语言转 API 调用**：将"帮我查一下明天从上海到北京的航班"解析为 `{"departure": "上海", "destination": "北京", "date": "2025-07-18"}`
- **数据自动提取**：从新闻文章中抽取出事件、时间、地点、人物等关键信息，并存入数据库

### 1.2 格式化生成的价值

格式化生成是连接 LLM 的自然语言理解能力和下游应用程序的程序化逻辑之间的关键。它使得：
- 前端应用能够直接解析和展示 LLM 输出
- 后端系统能够基于 LLM 输出执行自动化操作
- AI Agent 能够与外部工具和服务进行交互

---

## 二、Output Parsers

### 2.1 核心概念

LangChain 提供了一个强大的组件——`OutputParsers`（输出解析器），专门用于处理 LLM 的输出。其主要思想是在发送给 LLM 的提示（Prompt）中自动注入一段关于如何格式化输出的指令，并在得到结果后将 LLM 返回的纯文本字符串解析成预期的结构化数据。

### 2.2 PydanticOutputParser（推荐）

这是最强大的输出解析器，通过与 Pydantic 模型结合，可以实现对输出格式最严格的定义和验证。

**工作流程**：
1. 定义 Pydantic 数据模型
2. 生成格式指令
3. 构建并执行调用链
4. 解析与验证

**完整示例**：
```python
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from langchain.llms import OpenAI

# 1. 定义期望的数据结构
class PersonInfo(BaseModel):
    """用于存储个人信息的数据结构。"""
    name: str = Field(description="人物姓名")
    age: int = Field(description="人物年龄")
    skills: List[str] = Field(description="技能列表")

# 2. 基于 Pydantic 模型，创建解析器
parser = PydanticOutputParser(pydantic_object=PersonInfo)

# 3. 创建提示模板，注入格式指令
prompt = PromptTemplate(
    template="请根据以下文本提取信息。\n{format_instructions}\n{text}\n",
    input_variables=["text"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

# 4. 创建处理链
llm = OpenAI(temperature=0)
chain = prompt | llm | parser

# 5. 执行调用
text = "张三今年30岁，他擅长Python和Go语言。"
result = chain.invoke({"text": text})

# 6. 打印结果
print(result)
# name='张三' age=30 skills=['Python', 'Go语言']
```

**关键步骤详解**：

**步骤1：定义数据模型**
- 使用 Pydantic 的 `BaseModel` 定义 `PersonInfo` 类
- `Field` 中的 `description` 描述文本将直接作为指令提供给大模型
- 表述需要清晰准确，因为这会影响生成质量

**步骤2：生成格式指令**
- `get_format_instructions()` 方法会：
  1. 调用 Pydantic 模型的 `.model_json_schema()` 方法，提取 JSON Schema
  2. 对 Schema 进行简化，嵌入到预设的提示模板中
  3. 明确要求 LLM 输出一个符合该 Schema 的 JSON 对象

**步骤3：构建并执行调用链**
- 通过 LangChain 表达式语言（LCEL），将 `prompt`、`llm` 和 `parser` 链接起来
- `prompt` 会将用户输入和格式指令组合成最终的提示
- `llm` 根据提示生成 JSON 格式的字符串

**步骤4：解析与验证**
- 继承自 `JsonOutputParser`，先将字符串解析为 Python 字典
- 使用 `PersonInfo.model_validate()` 方法验证字典
- 如果验证通过，返回 `PersonInfo` 实例；否则抛出 `OutputParserException` 异常

### 2.3 其他输出解析器

**JsonOutputParser**
```python
from langchain.output_parsers import JsonOutputParser

parser = JsonOutputParser()
result = parser.parse("{\"name\": \"张三\", \"age\": 30}")
```

**StrOutputParser**
```python
from langchain.output_parsers import StrOutputParser

parser = StrOutputParser()
result = parser.parse("这是一段文本")
```

---

## 三、Function Calling（函数调用）

### 3.1 核心概念

Function Calling（或称 Tool Calling）是近年来 LLM 领域的一个重要进展，提升了模型与外部世界交互和生成结构化数据的能力。

### 3.2 工作流程

Function Calling 的本质是一个多轮对话流程：

**（1）定义工具**
在代码中以特定格式（通常是 JSON Schema）定义好可用的工具，包括工具的名称、功能描述、以及需要的参数。

**（2）用户提问**
用户发起一个需要调用工具才能回答的请求。

**（3）模型决策**
模型接收到请求后，分析用户的意图，并匹配最合适的工具。它不会直接回答，而是返回一个包含 `tool_calls` 的特殊响应。

**（4）代码执行**
应用接收到这个指令，解析出工具名称和参数，然后**在代码层面实际执行**这个工具（例如，调用一个真实的天气 API）。

**（5）结果反馈**
将工具的执行结果（例如，从 API 获取的真实天气数据）包装成一个 `role` 为 `tool` 的消息，再次发送给模型。

**（6）最终生成**
模型接收到工具的执行结果后，结合原始问题和工具返回的信息，生成最终的、自然的语言回答。

### 3.3 完整示例

```python
from openai import OpenAI

client = OpenAI()

# 1. 定义工具
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "获取指定城市的天气信息",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "城市名称"
                    }
                },
                "required": ["city"]
            }
        }
    }
]

# 2. 用户提问
messages = [{"role": "user", "content": "杭州今天天气怎么样？"}]

# 3. 第一次调用 (User -> Model)
response = client.chat.completions.create(
    model="gpt-4",
    messages=messages,
    tools=tools
)

message = response.choices[0].message

# 4. 处理 tool_calls
if message.tool_calls:
    tool_call = message.tool_calls[0]
    messages.append(message)  # 添加模型的回复
    
    # 执行工具（这里模拟）
    tool_output = "24℃，晴朗"  # 实际应该是调用真实 API
    messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "content": tool_output
    })
    
    # 5. 第二次调用 (Tool -> Model)
    final_response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        tools=tools
    )
    
    print(final_response.choices[0].message.content)
    # 输出: "根据查询结果，杭州今天的天气是24℃，晴朗。"
```

### 3.4 Function Calling 的优势

**vs 提示工程**：
- **可靠性更高**：模型原生支持，格式稳定、精确
- **意图识别**：不仅仅是格式化输出，更包含"意图到函数的映射"
- **类型安全**：通过 JSON Schema 定义参数类型，自动验证

**vs Output Parsers**：
- **更强大**：支持外部工具调用，而不仅是格式化输出
- **更灵活**：可以动态选择不同的函数
- **更智能**：模型主动选择最合适的工具

**核心价值**：
- 构建能执行实际任务的 AI 代理（Agent）
- 让 LLM 可以查询数据库、调用 API、控制智能家居等
- 是连接 LLM 与现实世界的桥梁

---

## 四、LlamaIndex 的结构化输出

### 4.1 核心概念

LlamaIndex 的输出解析与生成过程紧密结合，主要体现在两大核心组件中：
- **响应合成（Response Synthesis）**
- **结构化输出（Structured Output）**

### 4.2 响应合成器

在 RAG 流程中，检索器召回一系列相关的文本块（Nodes）后，并不是简单地将它们拼接起来。响应合成器负责接收这些文本块和原始查询，并以一种更智能的方式将它们呈现给 LLM 以生成最终答案。

**合成模式**：
- **refine 模式**：逐块处理信息并迭代地优化答案
- **compact 模式**：将尽可能多的文本块压缩进单次 LLM 调用中
- **tree_summarize 模式**：构建层次化的摘要树

### 4.3 Pydantic 程序（Pydantic Programs）

当需要 LLM 返回结构化数据（如 JSON）而非纯文本时，LlamaIndex 主要使用 **Pydantic 程序（Pydantic Programs）**。

**工作流程**：
1. **定义 Schema**：开发者定义一个 Pydantic 模型，明确所需输出的数据结构
2. **引导生成**：
   - 如果 LLM 支持 Function Calling，优先使用该功能
   - 否则，回退到将 JSON Schema 注入到提示词中的方法
3. **解析验证**：LLM 返回的输出会被自动解析并用 Pydantic 模型进行验证

```python
from llama_index.core.program import PydanticProgram
from pydantic import BaseModel

class Album(BaseModel):
    """数据模型，表示一个音乐专辑"""
    name: str
    artist: str

# 创建 Pydantic 程序
program = PydanticProgram.from_defaults(
    output_cls=Album,
    verbose=True,
)

# 执行程序
album = program(
    "The name of the album is 'The Dark Side of the Moon' "
    "and the artist is 'Pink Floyd'"
)

print(album)
# name='The Dark Side of the Moon' artist='Pink Floyd'
```

---

## 五、不依赖框架的实现思路

如果不想依赖特定的框架，也可以通过提示工程的技巧来实现格式化生成。

### 5.1 实用技巧

**1. 明确要求 JSON 格式**
```
请必须返回一个 JSON 对象。
不要包含任何解释性文字，只返回 JSON。
JSON 的格式应该是 {...}
```

**2. 提供 JSON Schema**
```
请返回一个 JSON 对象，格式如下：
{
  "name": "人物姓名（字符串）",
  "age": "人物年龄（整数）",
  "skills": "技能列表（字符串数组）"
}
```

**3. Few-shot 示例**
```
示例1：
输入: "张三今年30岁，擅长Python和Go"
输出: {"name": "张三", "age": 30, "skills": ["Python", "Go"]}

示例2：
输入: "李四25岁，会Java和C++"
输出: {"name": "李四", "age": 25, "skills": ["Java", "C++"]}

现在请处理：
输入: "王五28岁，精通JavaScript和Python"
输出:
```

**4. 使用语法约束**
对于一些本地部署的开源模型（如通过 `llama.cpp` 运行的模型），可以使用 GBNF (GGML BNF) 等语法文件来强制约束模型的输出，确保其生成的每一个 token 都严格符合预定义的 JSON 语法。

---

## 六、面试高频问题

### Q1: 为什么需要格式化生成？有哪些应用场景？

**参考答案**：
格式化生成让 LLM 输出结构化数据（如 JSON），而不是非结构化的文本。

**应用场景**：
1. **电商客服**：返回产品名称、价格、购买链接等，前端直接渲染商品卡片
2. **API 调用**：将自然语言转换为结构化的 API 请求参数
3. **数据提取**：从文章中抽取事件、时间、地点、人物等关键信息
4. **Agent 交互**：LLM 调用外部工具、查询数据库、控制设备

**价值**：
- 前端应用能够直接解析和展示 LLM 输出
- 后端系统能够基于 LLM 输出执行自动化操作
- AI Agent 能够与外部工具和服务进行交互

### Q2: PydanticOutputParser 的工作原理是什么？

**参考答案**：
PydanticOutputParser 通过四个步骤实现格式化生成：

**步骤1：定义数据模型**
- 使用 Pydantic 的 `BaseModel` 定义数据结构
- `Field` 中的 `description` 会作为指令提供给 LLM

**步骤2：生成格式指令**
- 调用 `get_format_instructions()` 方法
- 提取 Pydantic 模型的 JSON Schema
- 将 Schema 嵌入到提示模板中，明确要求 LLM 输出符合 Schema 的 JSON

**步骤3：构建调用链**
- 通过 LCEL 连接 `prompt | llm | parser`
- `prompt` 组合用户输入和格式指令
- `llm` 根据提示生成 JSON 字符串

**步骤4：解析与验证**
- 先将字符串解析为 Python 字典
- 使用 Pydantic 模型验证字典
- 验证通过返回实例，否则抛出异常

**优势**：
- 类型安全：自动验证数据类型
- 清晰定义：通过 Pydantic 模型明确输出格式
- 错误处理：验证失败时抛出异常

### Q3: Function Calling 是什么？它的工作流程是怎样的？

**参考答案**：
Function Calling（函数调用）是让 LLM 能够调用外部工具的技术。

**工作流程**：
1. **定义工具**：用 JSON Schema 定义工具的名称、功能、参数
2. **用户提问**：用户发起需要调用工具的请求
3. **模型决策**：LLM 分析意图，返回包含 `tool_calls` 的响应（选择哪个函数，用什么参数）
4. **代码执行**：应用解析工具名称和参数，实际执行工具（如调用 API）
5. **结果反馈**：将工具执行结果包装成 `role: tool` 的消息，发送给 LLM
6. **最终生成**：LLM 结合原始问题和工具结果，生成最终回答

**优势**：
- **可靠性高**：模型原生支持，格式稳定
- **意图识别**：自动选择最合适的工具
- **外部交互**：让 LLM 可以调用 API、查询数据库、控制设备

**核心价值**：
- 构建能执行实际任务的 AI Agent
- 连接 LLM 与现实世界的桥梁

### Q4: Function Calling vs Output Parsers，有什么区别？

**参考答案**：

**Function Calling**：
- **更强大**：支持外部工具调用，而不仅是格式化输出
- **更灵活**：可以动态选择不同的函数
- **更智能**：模型主动选择最合适的工具
- **应用场景**：Agent、工具调用、API 集成

**Output Parsers**：
- **更简单**：仅用于格式化输出，不涉及外部工具
- **更轻量**：不需要多轮对话
- **更可控**：通过 Pydantic 模型严格定义输出格式
- **应用场景**：数据提取、结构化输出

**选择建议**：
- 需要调用外部工具 → Function Calling
- 仅需格式化输出 → Output Parsers
- 复杂 Agent 系统 → Function Calling
- 简单数据提取 → Output Parsers

### Q5: 如何不依赖框架实现格式化生成？

**参考答案**：
不依赖框架时，可以使用以下技巧：

**1. 明确要求 JSON 格式**
```
请必须返回一个 JSON 对象。
不要包含任何解释性文字，只返回 JSON。
```

**2. 提供 JSON Schema**
```
请返回一个 JSON 对象，格式如下：
{
  "name": "人物姓名（字符串）",
  "age": "人物年龄（整数）"
}
```

**3. Few-shot 示例**
```
示例1：
输入: "张三30岁"
输出: {"name": "张三", "age": 30}

现在请处理：
输入: "李四25岁"
输出:
```

**4. 使用语法约束**
- 对于本地模型（如 llama.cpp），使用 GBNF 语法文件
- 强制约束模型输出，确保每个 token 都符合 JSON 语法
- 这是最严格也是最可靠的非 Function Calling 方法

**最佳实践**：
- 优先使用 Function Calling（如果模型支持）
- 其次使用 PydanticOutputParser
- 最后考虑纯提示工程

### Q6: 如何处理 LLM 不支持 Function Calling 的情况？

**参考答案**：
如果 LLM 不支持 Function Calling，可以使用以下方法：

**1. Output Parsers**
- 使用 PydanticOutputParser
- 将 JSON Schema 注入到提示词中
- 解析并验证 LLM 输出

```python
parser = PydanticOutputParser(pydantic_object=MyModel)
prompt = PromptTemplate(
    template="{format_instructions}\n{query}",
    partial_variables={"format_instructions": parser.get_format_instructions()}
)
```

**2. Few-shot Learning**
- 提供多个示例
- 展示期望的输出格式
- 让 LLM 学习模式

**3. 语法约束**
- 使用 GBNF 等语法文件
- 强制约束模型输出
- 适用于本地部署的开源模型

**4. 多轮对话**
- 第一轮：要求 LLM 返回 JSON
- 第二轮：如果格式不对，提示纠正
- 逐步引导 LLM 输出正确格式

**5. 后处理**
- 使用正则表达式提取 JSON
- 使用 JSON 解析器修复常见错误
- 对输出进行清洗和格式化

### Q7: 如何验证 LLM 输出的结构化数据？

**参考答案**：
验证 LLM 输出的方法：

**1. Pydantic 验证（推荐）**
```python
from pydantic import BaseModel, ValidationError

class Person(BaseModel):
    name: str
    age: int

try:
    person = Person.model_validate(json_string)
except ValidationError as e:
    print(f"验证失败: {e}")
```

**2. JSON Schema 验证**
```python
import jsonschema

schema = {
    "type": "object",
    "properties": {
        "name": {"type": "string"},
        "age": {"type": "integer"}
    },
    "required": ["name", "age"]
}

jsonschema.validate(instance=data, schema=schema)
```

**3. 手动验证**
```python
import json

try:
    data = json.loads(llm_output)
    assert "name" in data
    assert isinstance(data["age"], int)
except (json.JSONDecodeError, AssertionError) as e:
    print(f"验证失败: {e}")
```

**4. 重试机制**
- 如果验证失败，重新提示 LLM
- 提供错误信息，要求纠正
- 限制最大重试次数

### Q8: LlamaIndex 的结构化输出有什么特点？

**参考答案**：
LlamaIndex 的结构化输出主要体现在两个组件：

**1. 响应合成器（Response Synthesizer）**
- 负责将检索到的文本块和查询以智能方式呈现给 LLM
- 合成模式：
  - **refine**：逐块迭代优化答案
  - **compact**：压缩进单次 LLM 调用
  - **tree_summarize**：构建层次化摘要树

**2. Pydantic 程序（Pydantic Programs）**
- 用于生成结构化数据（如 JSON）
- 工作流程：
  1. 定义 Pydantic 模型（Schema）
  2. 如果 LLM 支持 Function Calling，优先使用
  3. 否则，将 JSON Schema 注入提示词
  4. 自动解析并用 Pydantic 模型验证

**优势**：
- 与 RAG 流程深度集成
- 支持多种合成模式
- 自动利用 Function Calling（如果可用）
- 类型安全的输出验证

**使用场景**：
- RAG 系统的结构化输出
- 知识图谱抽取
- 复杂数据提取
