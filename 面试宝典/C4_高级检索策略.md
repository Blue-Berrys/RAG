# C4: 高级检索策略

## 一、Text2SQL

### 1.1 什么是 Text2SQL？

Text2SQL 是一种将自然语言查询转换为结构化查询语言（SQL）的技术。它允许用户用自然语言提问，系统自动生成对应的 SQL 查询并从数据库中获取答案。

### 1.2 应用场景

- **数据分析**：业务分析师用自然语言查询数据
- **智能客服**：用户查询订单、账户信息等结构化数据
- **BI 系统**：非技术用户自助查询数据
- **RAG 系统**：结合结构化数据和非结构化文本的混合检索

### 1.3 技术实现

#### 方法一：基于 LLM 的 Text2SQL

```python
from langchain.chains import create_sql_query_chain
from langchain_community.utilities import SQLDatabase

# 连接数据库
db = SQLDatabase.from_uri("sqlite:///chinook.db")

# 创建 Text2SQL 链
chain = create_sql_query_chain(llm, db)

# 自然语言转 SQL
query = chain.invoke({"question": "列出销售额最高的5个员工"})
print(query)
# 输出: SELECT * FROM employees ORDER BY sales DESC LIMIT 5
```

#### 方法二：基于 Schema 的 Text2SQL

```python
# 提供数据库 Schema 信息
schema = """
CREATE TABLE employees (
    id INTEGER PRIMARY KEY,
    name TEXT,
    department TEXT,
    sales REAL
);
"""

# 结合 Schema 生成 SQL
prompt = f"""
数据库Schema:
{schema}

请根据以下问题生成SQL查询: {question}
"""
```

#### 方法三：Few-shot Learning

```python
examples = [
    {
        "question": "列出所有员工",
        "sql": "SELECT * FROM employees"
    },
    {
        "question": "销售额最高的员工",
        "sql": "SELECT * FROM employees ORDER BY sales DESC LIMIT 1"
    }
]

# 使用示例提示 LLM
prompt = few_shot_prompt + f"\n问题: {question}\nSQL:"
```

### 1.4 挑战与解决方案

**挑战 1：复杂查询**
- 多表 JOIN、子查询、聚合函数
- **解决**：提供示例、逐步生成、使用专门的 Text2SQL 模型

**挑战 2：Schema 理解**
- LLM 需要理解表结构、字段含义
- **解决**：提供详细的 Schema 注释、字段说明

**挑战 3：查询验证**
- 生成的 SQL 可能语法错误或逻辑错误
- **解决**：执行前验证、逐步调试、使用 SQL 解析器

---

## 二、元数据过滤

### 2.1 什么是元数据过滤？

元数据过滤是在向量检索的基础上，结合结构化元数据进行过滤，提升检索精确性。

### 2.2 应用场景

- **时间范围查询**：只检索最近 7 天的文档
- **类别过滤**：只检索特定类别（如"技术文档"）的文档
- **作者过滤**：只检索特定作者的内容
- **权限过滤**：只检索用户有权限访问的文档

### 2.3 实现方式

#### 方法一：预过滤（Pre-filtering）

```python
# 先过滤，再检索
filtered_docs = [doc for doc in docs if doc.metadata["date"] > "2024-01-01"]
results = vector_search(query, filtered_docs)
```

#### 方法二：后过滤（Post-filtering）

```python
# 先检索，再过滤
results = vector_search(query, docs, top_k=100)
filtered_results = [r for r in results if r.metadata["date"] > "2024-01-01"][:10]
```

#### 方法三：混合过滤（Hybrid Filtering）

```python
# 向量数据库支持的原生过滤
results = vector_store.search(
    query_vector=query_embedding,
    filter={
        "date": {"$gt": "2024-01-01"},
        "category": "技术文档"
    },
    top_k=10
)
```

### 2.4 最佳实践

**1. 过滤策略选择**
- **预过滤**：过滤条件严格，能大幅减少检索范围（如时间范围）
- **后过滤**：过滤条件宽松，需要结合相关性排序
- **混合过滤**：向量数据库原生支持，性能最优

**2. 元数据设计**
- 关键字段：时间、类别、作者、标签
- 索引优化：为常用过滤字段建立索引
- 数据类型：使用合适的数据类型（如日期、枚举）

**3. 性能优化**
- 缓存热门过滤条件的结果
- 批量过滤：一次处理多个查询
- 异步过滤：使用多线程/协程

---

## 三、多模态检索

### 3.1 什么是多模态检索？

多模态检索是指除了文本外，还支持检索图像、表格、音频、视频等多种模态的内容。

### 3.2 应用场景

- **图文检索**：输入文本检索相关图片，或输入图片检索相关文本
- **表格检索**：检索表格中的特定数据
- **多模态 RAG**：结合文本、图像、表格等多种信息生成答案

### 3.3 技术实现

#### 图像检索

**方法一：CLIP 模型**
```python
import clip
import torch

# 加载 CLIP 模型
model, preprocess = clip.load("ViT-B/32", device="cuda")

# 文本编码
text = "a dog sitting on a bench"
text_features = model.encode_text(clip.tokenize(text))

# 图像编码
image = preprocess(image).unsqueeze(0)
image_features = model.encode_image(image)

# 相似度计算
similarity = torch.cosine_similarity(text_features, image_features)
```

**方法二：图像描述 + 文本检索**
```python
# 1. 生成图像描述
caption = image_captioning_model.generate_caption(image)

# 2. 将描述作为文本进行检索
results = text_search(query, [caption])
```

#### 表格检索

**方法一：表格扁平化**
```python
# 将表格转换为 Markdown 格式
table_markdown = """
| 姓名 | 年龄 | 部门 |
| 张三 | 25 | 技术 |
| 李四 | 30 | 销售 |
"""

# 将 Markdown 作为文本检索
results = text_search(query, [table_markdown])
```

**方法二：表格语义编码**
```python
# 使用专门的表格编码模型（如 TAPAS）
from transformers import TAPASModel, TAPASTokenizer

tokenizer = TAPASTokenizer.from_pretrained("google/tapas-base-finetuned-wtq")
model = TAPASModel.from_pretrained("google/tapas-base-finetuned-wtq")

# 编码表格和查询
inputs = tokenizer(table=table, queries=query, return_tensors="pt")
outputs = model(**inputs)
```

### 3.4 挑战与解决方案

**挑战 1：跨模态语义对齐**
- 文本和图像的语义空间不同
- **解决**：使用 CLIP 等跨模态模型，统一语义空间

**挑战 2：表格结构复杂**
- 表格有多级表头、合并单元格等复杂结构
- **解决**：使用专门的表格解析工具（如 Camelot）

**挑战 3：计算开销大**
- 多模态模型计算复杂度高
- **解决**：使用轻量级模型、批量处理、GPU 加速

---

## 四、混合检索进阶

### 4.1 查询理解

#### 查询意图分类

```python
# 使用 LLM 分类查询意图
intent = llm.complete(f"""
分类以下查询的意图:
查询: {query}

意图类型:
1. 事实查询: "华为的营收是多少？"
2. 列表查询: "列出所有华为产品"
3. 操作查询: "如何设置华为手机？"
4. 对比查询: "华为和苹果哪个好？"
""")

# 根据意图选择检索策略
if intent == "事实查询":
    results = fact_search(query)
elif intent == "列表查询":
    results = list_search(query)
```

#### 实体识别与链接

```python
# 识别查询中的实体
entities = ner_model.extract_entities(query)
# ["华为", "营收"]

# 链接到知识库中的实体
linked_entities = entity_linking.link(entities)
# {"华为": "Company_123"}

# 使用实体信息增强检索
results = entity_aware_search(query, linked_entities)
```

### 4.2 检索结果融合

#### 加权融合

```python
def weighted_fusion(dense_results, sparse_results, w_dense=0.7, w_sparse=0.3):
    """
    加权融合
    """
    scores = {}
    for doc, score in dense_results:
        scores[doc] = scores.get(doc, 0) + w_dense * score

    for doc, score in sparse_results:
        scores[doc] = scores.get(doc, 0) + w_sparse * score

    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

#### 学习融合

```python
# 使用机器学习模型学习融合权重
from sklearn.ensemble import RandomForestRegressor

# 训练数据: (dense_score, sparse_score, relevance_label)
X_train = [[0.8, 0.3], [0.6, 0.9], ...]
y_train = [1, 0, 1, ...]  # 1: 相关, 0: 不相关

# 训练模型
model = RandomForestRegressor()
model.fit(X_train, y_train)

# 预测融合分数
fusion_score = model.predict([[dense_score, sparse_score]])
```

### 4.3 检索结果去重

#### 内容去重

```python
def deduplicate_by_content(results, threshold=0.9):
    """
    基于内容相似度去重
    """
    deduped = []
    for result in results:
        is_duplicate = False
        for existing in deduped:
            similarity = cosine_similarity(result.embedding, existing.embedding)
            if similarity > threshold:
                is_duplicate = True
                break
        if not is_duplicate:
            deduped.append(result)
    return deduped
```

#### 父文档去重

```python
# 基于父文档 ID 去重
seen_parent_ids = set()
deduped = []
for result in results:
    parent_id = result.metadata["parent_id"]
    if parent_id not in seen_parent_ids:
        seen_parent_ids.add(parent_id)
        deduped.append(result)
```

---

## 五、高级索引策略

### 5.1 分层索引

**原理**：根据文档的重要性或访问频率，构建多层索引。

```python
# 构建两层索引
hot_index = VectorIndex(hot_docs)  # 热点文档，使用高质量索引
cold_index = VectorIndex(cold_docs)  # 冷文档，使用轻量级索引

# 检索时优先查热索引
results = hot_index.search(query, top_k=10)
if len(results) < 10:
    results += cold_index.search(query, top_k=10-len(results))
```

### 5.2 自适应索引

**原理**：根据查询模式动态调整索引参数。

```python
# 根据查询复杂度调整 nprobe
query_complexity = estimate_complexity(query)
if query_complexity > 0.8:
    nprobe = 20  # 复杂查询，搜索更多桶
else:
    nprobe = 5   # 简单查询，搜索少量桶

results = ivf_index.search(query, nprobe=nprobe)
```

### 5.3 增量索引

**原理**：支持增量更新索引，避免全量重建。

```python
# Milvus 支持增量插入
new_docs = load_new_documents()
new_embeddings = embed(new_docs)
milvus_collection.insert([new_docs, new_embeddings])

# 自动在后台重建索引
milvus_collection.create_index(field_name="embedding", index_params={"index_type": "IVF_FLAT"})
```

---

## 六、面试高频问题

### Q1: 什么是 Text2SQL？它有什么应用场景？

**参考答案**：
Text2SQL 是一种将自然语言查询转换为 SQL 查询的技术。

**应用场景**：
1. **数据分析**：业务分析师用自然语言查询数据，无需写 SQL
2. **智能客服**：用户查询订单、账户信息等结构化数据
3. **BI 系统**：非技术用户自助查询数据
4. **RAG 系统**：结合结构化数据和非结构化文本的混合检索

**技术实现**：
1. **基于 LLM**：直接提示 LLM 生成 SQL
2. **基于 Schema**：提供数据库 Schema 信息辅助生成
3. **Few-shot Learning**：提供示例帮助 LLM 理解模式

**挑战**：
1. **复杂查询**：多表 JOIN、子查询、聚合函数
2. **Schema 理解**：需要理解表结构、字段含义
3. **查询验证**：生成的 SQL 可能语法或逻辑错误

### Q2: 什么是元数据过滤？有哪些实现方式？

**参考答案**：
元数据过滤是在向量检索的基础上，结合结构化元数据进行过滤，提升检索精确性。

**应用场景**：
- 时间范围查询：只检索最近 7 天的文档
- 类别过滤：只检索特定类别的文档
- 作者过滤：只检索特定作者的内容
- 权限过滤：只检索用户有权限访问的文档

**实现方式**：
1. **预过滤**：先过滤，再检索。适合过滤条件严格，能大幅减少检索范围
2. **后过滤**：先检索，再过滤。适合过滤条件宽松，需要结合相关性排序
3. **混合过滤**：向量数据库原生支持，性能最优

**最佳实践**：
- 合理选择过滤策略（预过滤 vs 后过滤 vs 混合过滤）
- 设计合理的元数据（时间、类别、作者、标签）
- 为常用过滤字段建立索引
- 缓存热门过滤条件的结果

### Q3: 什么是多模态检索？如何实现？

**参考答案**：
多模态检索是指除了文本外，还支持检索图像、表格、音频、视频等多种模态的内容。

**实现方式**：

**图像检索**：
1. **CLIP 模型**：统一文本和图像的语义空间，直接计算相似度
2. **图像描述 + 文本检索**：生成图像描述，将描述作为文本检索

**表格检索**：
1. **表格扁平化**：将表格转换为 Markdown/CSV 格式，作为文本检索
2. **表格语义编码**：使用专门的表格编码模型（如 TAPAS）

**挑战**：
1. **跨模态语义对齐**：文本和图像的语义空间不同，使用 CLIP 等跨模态模型
2. **表格结构复杂**：使用专门的表格解析工具（如 Camelot）
3. **计算开销大**：使用轻量级模型、批量处理、GPU 加速

### Q4: 如何进行查询意图分类？有什么作用？

**参考答案**：
查询意图分类是识别用户查询的意图类型，以便选择最合适的检索策略。

**常见意图类型**：
1. **事实查询**："华为的营收是多少？" → 精确匹配检索
2. **列表查询**："列出所有华为产品" → 范围检索
3. **操作查询**："如何设置华为手机？" → 教程文档检索
4. **对比查询**："华为和苹果哪个好？" → 对比检索

**实现方式**：
```python
# 使用 LLM 分类查询意图
intent = llm.complete(f"""
分类以下查询的意图:
查询: {query}
意图类型: 1.事实查询 2.列表查询 3.操作查询 4.对比查询
""")

# 根据意图选择检索策略
if intent == "事实查询":
    results = fact_search(query)
elif intent == "列表查询":
    results = list_search(query)
```

**作用**：
- 提升检索精确性
- 优化用户体验
- 降低检索成本（不同意图使用不同策略）

### Q5: 如何实现检索结果融合？

**参考答案**：
检索结果融合是将多个检索结果合并，提升最终结果的质量。

**融合方法**：
1. **RRF（Reciprocal Rank Fusion）**：
   - 公式：`score(doc) = Σ 1/(k + rank + 1)`，k 默认为 60
   - 优势：简单有效，无需调参

2. **加权融合**：
   - 公式：`score = w_dense * score_dense + w_sparse * score_sparse`
   - 需要调整权重（如 w_dense=0.7, w_sparse=0.3）

3. **学习融合**：
   - 使用机器学习模型学习融合权重
   - 需要训练数据（检索分数 + 相关性标签）

**选择建议**：
- 快速实现：RRF
- 可调优场景：加权融合
- 有训练数据：学习融合

### Q6: 如何实现检索结果去重？

**参考答案**：
检索结果去重是去除重复或高度相似的结果，提升结果多样性。

**去重方法**：
1. **基于内容相似度去重**：
   ```python
   # 计算内容相似度，超过阈值则去重
   similarity = cosine_similarity(result1.embedding, result2.embedding)
   if similarity > 0.9:
       # 去重
   ```

2. **基于父文档 ID 去重**：
   ```python
   # 如果多个结果来自同一父文档，只保留一个
   seen_parent_ids = set()
   deduped = []
   for result in results:
       parent_id = result.metadata["parent_id"]
       if parent_id not in seen_parent_ids:
           deduped.append(result)
   ```

3. **基于 URL 去重**：
   ```python
   # 如果多个结果来自同一 URL，只保留一个
   seen_urls = set()
   deduped = [r for r in results if r.metadata["url"] not in seen_urls]
   ```

### Q7: 什么是分层索引？有什么优势？

**参考答案**：
分层索引是根据文档的重要性或访问频率，构建多层索引。

**实现方式**：
```python
# 构建两层索引
hot_index = VectorIndex(hot_docs)  # 热点文档，使用高质量索引
cold_index = VectorIndex(cold_docs)  # 冷文档，使用轻量级索引

# 检索时优先查热索引
results = hot_index.search(query, top_k=10)
if len(results) < 10:
    results += cold_index.search(query, top_k=10-len(results))
```

**优势**：
1. **性能优化**：热点文档使用高质量索引，提升检索速度
2. **成本优化**：冷文档使用轻量级索引，降低内存占用
3. **灵活扩展**：可根据访问模式动态调整分层策略

**应用场景**：
- 新闻网站（最新文章热点高）
- 电商（热门商品访问频繁）
- 文档管理（近期文档访问多）

### Q8: 如何优化 Text2SQL 的准确性？

**参考答案**：
优化 Text2SQL 准确性的方法：

**1. 提供详细的 Schema 信息**
```python
schema = """
CREATE TABLE employees (
    id INTEGER PRIMARY KEY,
    name TEXT,  -- 员工姓名
    department TEXT,  -- 部门名称
    sales REAL  -- 销售额（单位：万元）
);
"""
```

**2. 使用 Few-shot Learning**
```python
examples = [
    {"question": "列出所有员工", "sql": "SELECT * FROM employees"},
    {"question": "销售额最高的员工", "sql": "SELECT * FROM employees ORDER BY sales DESC LIMIT 1"}
]
```

**3. 分步生成复杂查询**
- 先生成简单查询
- 逐步添加 JOIN、WHERE、GROUP BY 等子句
- 每步验证 SQL 语法

**4. 使用专门的 Text2SQL 模型**
- 如 T5-3B、SQLCoder
- 这些模型在 SQL 生成任务上表现更好

**5. 查询验证**
- 执行前验证 SQL 语法
- 使用 SQL 解析器检查逻辑
- 逐步调试，定位错误

### Q9: 如何处理表格数据的检索？

**参考答案**：
处理表格数据检索的方法：

**1. 表格扁平化（简单）**
```python
# 将表格转换为 Markdown 格式
table_markdown = """
| 姓名 | 年龄 | 部门 |
| 张三 | 25 | 技术 |
| 李四 | 30 | 销售 |
"""
# 将 Markdown 作为文本检索
results = text_search(query, [table_markdown])
```

**2. 表格语义编码（高级）**
```python
# 使用专门的表格编码模型（如 TAPAS）
from transformers import TAPASModel, TAPASTokenizer

tokenizer = TAPASTokenizer.from_pretrained("google/tapas-base-finetuned-wtq")
model = TAPASModel.from_pretrained("google/tapas-base-finetuned-wtq")

# 编码表格和查询
inputs = tokenizer(table=table, queries=query, return_tensors="pt")
outputs = model(**inputs)
```

**3. 混合检索**
- 表格标题 + 文本检索
- 表格内容 + 结构化查询

**最佳实践**：
- 简单表格：扁平化 + 文本检索
- 复杂表格：TAPAS 等专用模型
- 大量表格：建立表格索引，结合元数据过滤