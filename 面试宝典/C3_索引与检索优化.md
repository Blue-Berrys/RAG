# C3: 索引与检索优化

## 一、向量数据库选择

### 1.1 向量数据库的作用

向量数据库是 RAG 系统的核心组件，负责：
- **存储向量嵌入**：将文本通过嵌入模型转换为向量后存储
- **高效相似度搜索**：快速找到与查询向量最相似的内容
- **元数据管理**：关联文本来源、页码等元数据信息

### 1.2 主流向量数据库对比

#### 大规模生产级

**Milvus**
- **特点**：开源、高性能、支持多种索引类型（IVF、HNSW、DiskANN）
- **优势**：
  - 支持数十亿级向量规模
  - 丰富的索引类型和相似度度量
  - 支持标量过滤与向量检索混合查询
  - 云原生架构，支持 Kubernetes 部署
- **适用场景**：大规模生产环境、需要复杂查询的场景

**Pinecone**
- **特点**：全托管向量数据库服务
- **优势**：
  - 无需运维，开箱即用
  - 自动扩缩容
  - 低延迟、高可用
- **劣势**：闭源、成本较高
- **适用场景**：快速原型开发、不想运维数据库的团队

#### 轻量级/本地化

**FAISS**
- **特点**：Facebook 开源向量相似度搜索库
- **优势**：
  - 轻量级，可直接集成到应用中
  - 支持多种索引类型（Flat、IVF、HNSW）
  - 无需额外服务部署
- **劣势**：
  - 不支持持久化存储（需手动管理）
  - 不支持元数据过滤
  - 单机限制
- **适用场景**：原型开发、小规模应用、离线处理

**Chroma**
- **特点**：开源嵌入数据库，专为 AI/LLM 设计
- **优势**：
  - 开箱即用，简单易用
  - 支持元数据过滤
  - 支持持久化存储
  - 与 LangChain/LlamaIndex 深度集成
- **适用场景**：中小规模应用、快速开发

### 1.3 选择建议

| 场景 | 推荐方案 |
|------|---------|
| **大规模生产（>1000万向量）** | Milvus |
| **快速原型、不想运维** | Pinecone |
| **小规模应用（<100万向量）** | Chroma |
| **离线处理、嵌入应用** | FAISS |

---

## 二、索引构建优化

### 2.1 索引类型选择

向量数据库支持多种索引类型，不同的索引类型在查询速度、准确率和内存占用上有不同的权衡：

#### Flat 索引（精确搜索）
- **原理**：暴力搜索，计算查询向量与所有向量的距离
- **优势**：100% 召回率
- **劣势**：查询速度慢，O(n) 复杂度
- **适用场景**：小规模数据（<10万向量）

#### IVF（Inverted File Index）
- **原理**：通过聚类将向量分为多个桶，查询时只搜索最近的桶
- **参数**：
  - `nlist`：聚类中心数量（推荐值：√n，n 为向量总数）
  - `nprobe`：搜索的桶数量（越大召回率越高，但速度越慢）
- **优势**：查询速度快，召回率可控
- **适用场景**：中等规模数据（10万-1000万向量）

#### HNSW（Hierarchical Navigable Small World）
- **原理**：构建多层图结构，上层稀疏、下层密集
- **参数**：
  - `M`：每个节点的最大连接数（默认 16）
  - `efConstruction`：构建时的搜索深度（默认 200）
  - `ef`：查询时的搜索深度（默认 10）
- **优势**：查询速度极快，召回率高
- **劣势**：内存占用大，构建时间长
- **适用场景**：需要高查询性能的场景

#### DiskANN
- **原理**：基于图的磁盘索引，将部分图结构存储在磁盘上
- **优势**：内存占用低，支持超大规模数据
- **适用场景**：内存受限的超大规模场景

### 2.2 索引构建最佳实践

**1. 选择合适的嵌入模型**
- **中文**：bge-small-zh-v1.5（512维）、bge-large-zh-v1.5（1024维）、m3e-base（768维）
- **英文**：all-MiniLM-L6-v2（384维）、text-embedding-ada-002（1536维）
- **多语言**：bge-m3（1024维）、multilingual-e5（1024维）

**2. 向量归一化**
```python
# 对向量进行 L2 归一化，可以使用内积代替余弦相似度
embeddings = np.array(embeddings)
normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
```

**3. 批量插入**
- 使用批量插入而非单条插入，提升索引构建速度
- 批量大小推荐：1000-10000

**4. 元数据设计**
- 关键元数据：来源文档、页码、章节、时间戳
- 结构化元数据：便于后续过滤查询

---

## 三、检索优化策略

### 3.1 混合检索（Hybrid Search）

#### 为什么需要混合检索？

**纯向量检索的问题**：
- 无法精确匹配关键词（如人名、专有名词）
- 对于稀疏特征（如 ID、编号）效果差
- 可能召回语义相似但无关的内容

**BM25 检索的优势**：
- 精确匹配关键词
- 对稀疏特征效果好
- 基于词频统计，可解释性强

**混合检索的优势**：
- 结合语义理解和关键词匹配
- 提升召回率和精确率
- 互补优势，覆盖更多场景

#### 实现方式

**1. Dense + Sparse 检索**
```python
# 伪代码示例
dense_results = vector_search(query_embedding, top_k=20)  # 向量检索
sparse_results = bm25_search(query_keywords, top_k=20)    # BM25检索

# RRF 融合
final_results = reciprocal_rank_fusion(dense_results, sparse_results, top_k=10)
```

**2. RRF（Reciprocal Rank Fusion）**

RRF 是一种简单有效的融合方法：

```python
def reciprocal_rank_fusion(results_list, k=60):
    """
    results_list: 多个检索结果列表
    k: 平滑参数，默认60
    """
    scores = {}
    for results in results_list:
        for rank, doc in enumerate(results):
            if doc not in scores:
                scores[doc] = 0
            scores[doc] += 1 / (k + rank + 1)

    # 按分数排序
    sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return [doc for doc, score in sorted_docs]
```

**RRF 的优势**：
- 无需调参，k=60 在大多数场景下效果良好
- 对不同检索方法的分数分布不敏感
- 简单高效，易于实现

### 3.2 重排序（Reranking）

#### 为什么需要重排序？

**初步检索的问题**：
- 检索结果可能包含噪声
- 相关性排序可能不够精确
- Top-K 结果中可能只有部分真正相关

**重排序的作用**：
- 对初步检索结果进行精细排序
- 提升最终传给 LLM 的上下文质量
- 使用更强大的模型进行二轮筛选

#### 重排序方法

**1. Cross-Encoder 重排序**
```python
from sentence_transformers import CrossEncoder

# 加载重排序模型
reranker = CrossEncoder('BAAI/bge-reranker-base')

# 初步检索结果
query = "用户查询"
docs = ["文档1", "文档2", "文档3", ...]

# 重排序
pairs = [[query, doc] for doc in docs]
scores = reranker.predict(pairs)

# 按分数排序
reranked_docs = [doc for _, doc in sorted(zip(scores, docs), reverse=True)]
```

**2. LLM 重排序**
- 使用 LLM 对检索结果打分
- 更智能，但成本高、速度慢

**3. 规则重排序**
- 按元数据过滤（如时间、来源）
- 按关键词匹配度加权
- 按文档长度或点击率排序

### 3.3 查询重写（Query Rewrite）

#### 为什么需要查询重写？

**用户查询的问题**：
- 表达不清晰或有歧义
- 缺少关键上下文信息
- 单轮查询无法表达复杂意图

**查询重写的作用**：
- 将用户查询转换为更适合检索的形式
- 补充缺失的上下文信息
- 生成多个查询变体，提升召回率

#### 重写方法

**1. 查询扩展**
```python
# 提取关键词
keywords = extract_keywords(query)

# 生成同义词、相关词
expanded_query = query + " " + " ".join(keywords + synonyms)
```

**2. 查询分解**
- 将复杂查询分解为多个子查询
- 分别检索后合并结果

**3. LLM 重写**
```python
# 使用 LLM 重写查询
rewritten_query = llm.complete(
    f"请将以下查询重写为更适合检索的形式，保持原意不变：{query}"
)
```

**4. 历史查询融合**
- 在多轮对话中，融合历史查询信息
- 补充上下文，明确指代关系

### 3.4 父子文档检索

#### 为什么需要父子文档？

**问题场景**：
- 小块检索精确，但上下文不完整
- 大块上下文完整，但检索不精确

**父子文档解决方案**：
- **子文档**：用于检索，小块精确匹配
- **父文档**：用于生成，大块保持完整性

#### 实现方式

**1. LangChain ParentDocumentRetriever**
```python
from langchain.retrievers import ParentDocumentRetriever
from langchain.storage import InMemoryStore
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 子块分割器（用于检索）
child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)

# 父块分割器（用于生成）
parent_splitter = RecursiveCharacterTextSplitter(chunk_size=800)

# 向量数据库
vectorstore = Chroma(collection_name="full_documents", embedding_function=embeddings)

# 存储层
store = InMemoryStore()

# 创建检索器
retriever = ParentDocumentRetriever(
    vectorstore=vectorstore,
    docstore=store,
    child_splitter=child_splitter,
    parent_splitter=parent_splitter,
)
```

**工作流程**：
1. **索引构建**：
   - 文档按父块大小（800）分割
   - 每个父块再按子块大小（200）分割
   - 子块向量化存入向量数据库
   - 父块存入文档存储，建立父子关联

2. **检索阶段**：
   - 查询向量化，在子块中检索
   - 找到相关的子块

3. **生成阶段**：
   - 返回子块对应的父文档
   - 保持上下文完整性

### 3.5 递归检索

#### 原理

递归检索适用于有层级结构的文档（如书籍、报告）：

1. **检索节点**：先检索高层节点（如章节）
2. **递归下钻**：根据相关性递归检索子节点（如小节、段落）
3. **合并结果**：将多层检索结果合并

#### 实现方式

**LlamaIndex 递归检索**：
```python
from llama_index.core.retrievers import RecursiveRetriever

# 构建层级索引
documents = SimpleDirectoryReader(data_path).load_data()
node_parser = SimpleNodeParser.from_defaults(nodes=nodes)

# 构建层级结构
nodes = node_parser.build_tree_from_documents(documents)

# 创建递归检索器
retriever = RecursiveRetriever(
    root_id="root",
    retriever_dict={
        "root": vector_retriever,
        "section": section_retriever,
        "paragraph": paragraph_retriever,
    }
)
```

**优势**：
- 保持文档层级结构
- 先粗后细，逐步定位
- 适合结构化文档

### 3.6 自动合并检索

#### 原理

自动合并检索在检索到相关片段后，自动查找相邻片段并合并，确保上下文完整性。

#### 实现方式

```python
from llama_index.core.retrievers import AutoMergingRetriever

# 基础检索器
base_retriever = vector_index.as_retriever(similarity_top_k=10)

# 自动合并检索器
retriever = AutoMergingRetriever(
    base_retriever,
    alpha=0.5,  # 合并阈值
    threshold=2  # 最少合并片段数
)
```

**工作流程**：
1. 基础检索器检索到相关片段
2. 查找片段的父节点
3. 如果父节点下的子节点检索到一定数量（threshold），则返回整个父节点
4. 否则返回原始检索结果

---

## 四、检索评估与优化

### 4.1 检索评估指标

#### 基于标注数据的指标

**1. Precision@K**
- 定义：前 K 个结果中相关文档的比例
- 公式：`Precision@K = 相关文档数 / K`
- 评价：检索结果的准确性

**2. Recall@K**
- 定义：前 K 个结果中相关文档占所有相关文档的比例
- 公式：`Recall@K = 检索到的相关文档数 / 所有不相关文档总数`
- 评价：检索结果的完整性

**3. F1@K**
- 定义：Precision 和 Recall 的调和平均
- 公式：`F1 = 2 * (Precision * Recall) / (Precision + Recall)`
- 评价：综合性能

**4. MRR（Mean Reciprocal Rank）**
- 定义：第一个相关文档排名倒数的平均值
- 公式：`MRR = (1/|Q|) * Σ(1/rank_q)`
- 评价：第一个相关结果的排名质量

**5. MAP（Mean Average Precision）**
- 定义：每个查询的平均精确率的平均值
- 公式：`MAP = (1/|Q|) * Σ(AP(q))`
- 评价：整体排序质量

#### 无标注数据指标

**1. 平均检索延迟**
- 评价：检索速度

**2. 吞吐量（QPS）**
- 评价：系统并发能力

### 4.2 A/B 测试

**测试方法**：
1. 准备两个版本的检索系统（如不同索引类型、不同重排序策略）
2. 分流用户请求（如 50% 到 A 版本，50% 到 B 版本）
3. 收集用户反馈（点击率、停留时间、满意度）
4. 统计分析，判断是否有显著差异

### 4.3 优化建议

**1. 索引优化**
- 选择合适的索引类型（大规模用 HNSW，小规模用 Flat）
- 调整索引参数（nprobe、ef 等）
- 定期重建索引（数据更新后）

**2. 检索优化**
- 使用混合检索（向量 + BM25）
- 添加重排序模块
- 实现查询重写
- 使用父子文档或递归检索

**3. 缓存优化**
- 缓存热门查询的检索结果
- 缓存文档向量化结果
- 使用 Redis 等内存数据库

**4. 并行化**
- 并行执行多个检索查询
- 批量处理检索请求
- 使用异步 I/O

---

## 五、面试高频问题

### Q1: 向量数据库有哪些主流选择？如何选型？

**参考答案**：
**大规模生产级**：
- **Milvus**：开源、高性能、支持多种索引类型（IVF、HNSW、DiskANN），适合千万级以上向量规模
- **Pinecone**：全托管、无运维、自动扩缩容，适合快速原型开发

**轻量级/本地化**：
- **FAISS**：轻量级、可嵌入应用、无持久化，适合离线处理和小规模应用
- **Chroma**：简单易用、支持元数据过滤、与 LangChain 深度集成，适合中小规模应用

**选型建议**：
- >1000万向量：Milvus
- 快速原型、不想运维：Pinecone
- <100万向量：Chroma
- 离线处理：FAISS

### Q2: 什么是混合检索？为什么需要它？

**参考答案**：
混合检索结合了**向量检索（Dense）**和**关键词检索（Sparse，如 BM25）**的优势。

**为什么需要**：
1. **互补优势**：
   - 向量检索：理解语义，但无法精确匹配关键词
   - BM25检索：精确匹配关键词，对专有名词、ID 效果好

2. **提升召回率**：覆盖更多相关文档
3. **提升精确率**：过滤语义相似但无关的内容

**实现方式**：
- **Dense + Sparse 检索**：分别执行向量检索和 BM25 检索
- **RRF 融合**：使用倒数排名融合（Reciprocal Rank Fusion）合并结果
- **简单公式**：`score(doc) = Σ 1/(k + rank + 1)`，k 默认为 60

### Q3: 什么是重排序？为什么需要它？

**参考答案**：
重排序是对初步检索结果进行精细排序的过程。

**为什么需要**：
1. **初步检索有噪声**：可能召回不相关或相关性低的内容
2. **提升排序质量**：使用更强大的模型进行二轮筛选
3. **改善生成质量**：确保 LLM 看到的都是高质量上下文

**重排序方法**：
1. **Cross-Encoder**：使用专门的重排序模型（如 bge-reranker-base），对 query-doc 对打分
2. **LLM 重排序**：使用 LLM 对检索结果打分，更智能但成本高
3. **规则重排序**：按元数据、关键词匹配度等规则排序

**最佳实践**：
- 初步检索召回 50-100 个结果
- 使用 Cross-Encoder 重排序
- 取 Top-10 或 Top-20 传给 LLM

### Q4: 什么是父子文档检索？它解决了什么问题？

**参考答案**：
父子文档检索是一种"**小块检索，大块生成**"的策略。

**解决的问题**：
- **小块检索**：精确匹配，但上下文不完整
- **大块检索**：上下文完整，但检索不精确

**解决方案**：
1. **子文档（小块）**：用于检索，快速定位相关内容（如 200 字）
2. **父文档（大块）**：用于生成，保持上下文完整性（如 800 字）

**工作流程**：
1. **索引构建**：文档按父块分割 → 每个父块再按子块分割 → 子块向量化 → 建立父子关联
2. **检索阶段**：查询向量化 → 在子块中检索 → 找到相关子块
3. **生成阶段**：返回子块对应的父文档 → 保持上下文完整性

**示例**：
- 用户问"宫保鸡丁需要什么调料"
- 子块检索到"必备原料和工具"章节（200 字）
- 生成时返回整个菜谱文档（800 字），包含完整的原料、步骤、附加内容

### Q5: 向量数据库的索引类型有哪些？如何选择？

**参考答案**：

**1. Flat 索引（暴力搜索）**
- 原理：计算查询向量与所有向量的距离
- 优势：100% 召回率
- 劣势：查询慢，O(n) 复杂度
- 适用：小规模数据（<10万向量）

**2. IVF（Inverted File Index）**
- 原理：聚类分桶，查询时搜索最近的桶
- 参数：nlist（聚类数）、nprobe（搜索桶数）
- 优势：查询快，召回率可控
- 适用：中等规模（10万-1000万向量）

**3. HNSW（Hierarchical Navigable Small World）**
- 原理：多层图结构，上层稀疏、下层密集
- 参数：M（连接数）、efConstruction（构建深度）、ef（查询深度）
- 优势：查询极快，召回率高
- 劣势：内存占用大
- 适用：需要高查询性能的场景

**4. DiskANN**
- 原理：基于图的磁盘索引
- 优势：内存占用低，支持超大规模
- 适用：内存受限的超大规模场景

**选择建议**：
- <10万：Flat
- 10万-1000万：IVF 或 HNSW
- >1000万：HNSW 或 DiskANN

### Q6: 如何评估检索系统的性能？

**参考答案**：

**基于标注数据的指标**：
1. **Precision@K**：前 K 个结果中相关文档的比例（准确性）
2. **Recall@K**：前 K 个结果中相关文档占所有相关文档的比例（完整性）
3. **F1@K**：Precision 和 Recall 的调和平均（综合性能）
4. **MRR**：第一个相关文档排名倒数的平均值（首个结果质量）
5. **MAP**：每个查询的平均精确率的平均值（整体排序质量）

**无标注数据指标**：
1. **平均检索延迟**：检索速度
2. **吞吐量（QPS）**：系统并发能力
3. **内存/CPU 占用**：资源消耗

**端到端评估**：
- 用户反馈（点击率、满意度）
- A/B 测试
- 线上监控

### Q7: 什么是查询重写？有哪些方法？

**参考答案**：
查询重写是将用户查询转换为更适合检索的形式。

**为什么需要**：
- 用户查询表达不清晰或有歧义
- 缺少关键上下文信息
- 单轮查询无法表达复杂意图

**重写方法**：
1. **查询扩展**：提取关键词，生成同义词、相关词
2. **查询分解**：将复杂查询分解为多个子查询，分别检索后合并
3. **LLM 重写**：使用 LLM 重写查询，更智能但成本高
4. **历史查询融合**：在多轮对话中融合历史信息，补充上下文

**示例**：
- 原查询："怎么做？"
- 重写后："宫保鸡丁怎么做？"（补充上下文）

### Q8: 如何优化检索速度？

**参考答案**：

**1. 索引优化**
- 选择合适的索引类型（HNSW 查询快，Flat 召回全）
- 调整索引参数（降低 nprobe、ef 可提升速度但降低召回率）
- 定期重建索引

**2. 检索优化**
- 减少检索数量（top_k 从 100 降到 10）
- 使用混合检索提升精确率，减少重排序压力
- 添加缓存（热门查询、向量结果）

**3. 系统优化**
- 批量处理检索请求
- 并行执行多个检索查询
- 使用异步 I/O
- 增加机器资源（水平扩展）

**4. 硬件优化**
- 使用 GPU 加速向量计算
- 使用 SSD 存储索引
- 增加内存容量

**权衡**：
- 速度 vs 召回率：降低 nprobe/ef 可提升速度但降低召回率
- 成本 vs 性能：增加机器资源可提升性能但增加成本

### Q9: 什么是递归检索？它适合什么场景？

**参考答案**：
递归检索适用于有层级结构的文档（如书籍、报告），先检索高层节点，再递归检索子节点。

**工作流程**：
1. **检索节点**：先检索高层节点（如章节）
2. **递归下钻**：根据相关性递归检索子节点（如小节、段落）
3. **合并结果**：将多层检索结果合并

**优势**：
- 保持文档层级结构
- 先粗后细，逐步定位
- 适合结构化文档

**实现**：
- LlamaIndex 提供 `RecursiveRetriever`
- 可配置不同层级的检索器（root/section/paragraph）
- 支持自定义检索策略

**适用场景**：
- 书籍、技术文档
- 法律文档、医疗指南
- 任何有明确层级结构的文档