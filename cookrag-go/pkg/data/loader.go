package data

import (
	"context"
	"encoding/csv"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"

	"github.com/charmbracelet/log"
	"cookrag-go/internal/models"
)

// DocumentLoader æ–‡æ¡£åŠ è½½å™¨æ¥å£
type DocumentLoader interface {
	Load(ctx context.Context) ([]models.Document, error)
}

// JSONLoader JSONæ–‡ä»¶åŠ è½½å™¨
type JSONLoader struct {
	filePath string
}

// NewJSONLoader åˆ›å»ºJSONåŠ è½½å™¨
func NewJSONLoader(filePath string) *JSONLoader {
	return &JSONLoader{
		filePath: filePath,
	}
}

// Load åŠ è½½JSONæ–‡æ¡£
func (l *JSONLoader) Load(ctx context.Context) ([]models.Document, error) {
	log.Infof("ğŸ“„ Loading JSON documents from: %s", l.filePath)

	file, err := os.Open(l.filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	var docs []models.Document
	decoder := json.NewDecoder(file)

	if err := decoder.Decode(&docs); err != nil {
		return nil, fmt.Errorf("failed to decode JSON: %w", err)
	}

	log.Infof("âœ… Loaded %d documents from JSON", len(docs))
	return docs, nil
}

// TextLoader æ–‡æœ¬æ–‡ä»¶åŠ è½½å™¨
type TextLoader struct {
	directory string
	ext       []string
}

// NewTextLoader åˆ›å»ºæ–‡æœ¬åŠ è½½å™¨
func NewTextLoader(directory string, ext []string) *TextLoader {
	return &TextLoader{
		directory: directory,
		ext:       ext,
	}
}

// Load åŠ è½½æ–‡æœ¬æ–‡ä»¶
func (l *TextLoader) Load(ctx context.Context) ([]models.Document, error) {
	log.Infof("ğŸ“„ Loading text files from: %s", l.directory)

	var docs []models.Document

	err := filepath.Walk(l.directory, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if info.IsDir() {
			return nil
		}

		// æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
		if !l.matchesExt(path) {
			return nil
		}

		// è¯»å–æ–‡ä»¶
		content, err := os.ReadFile(path)
		if err != nil {
			log.Warnf("âš ï¸  Failed to read file %s: %v", path, err)
			return nil
		}

		doc := models.Document{
			ID:      generateDocID(path),
			Content: string(content),
			Metadata: map[string]interface{}{
				"source": path,
				"size":   info.Size(),
				"mod_time": info.ModTime(),
			},
		}

		docs = append(docs, doc)
		return nil
	})

	if err != nil {
		return nil, fmt.Errorf("failed to walk directory: %w", err)
	}

	log.Infof("âœ… Loaded %d text files", len(docs))
	return docs, nil
}

// matchesExt æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
func (l *TextLoader) matchesExt(path string) bool {
	if len(l.ext) == 0 {
		return true
	}

	ext := strings.ToLower(filepath.Ext(path))
	for _, e := range l.ext {
		if strings.ToLower(e) == ext {
			return true
		}
	}
	return false
}

// CSLoader CSVæ–‡ä»¶åŠ è½½å™¨
type CSVLoader struct {
	filePath   string
	contentCol int    // å†…å®¹åˆ—ç´¢å¼•
	metaCols   []int  // å…ƒæ•°æ®åˆ—ç´¢å¼•
	hasHeader  bool   // æ˜¯å¦æœ‰è¡¨å¤´
}

// NewCSVLoader åˆ›å»ºCSVåŠ è½½å™¨
func NewCSVLoader(filePath string, contentCol int, metaCols []int, hasHeader bool) *CSVLoader {
	return &CSVLoader{
		filePath:   filePath,
		contentCol: contentCol,
		metaCols:   metaCols,
		hasHeader:  hasHeader,
	}
}

// Load åŠ è½½CSVæ–‡æ¡£
func (l *CSVLoader) Load(ctx context.Context) ([]models.Document, error) {
	log.Infof("ğŸ“„ Loading CSV documents from: %s", l.filePath)

	file, err := os.Open(l.filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	reader := csv.NewReader(file)
	reader.Comma = ','

	var docs []models.Document
	rowNum := 0

	for {
		record, err := reader.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, fmt.Errorf("failed to read CSV: %w", err)
		}

		rowNum++

		// è·³è¿‡è¡¨å¤´
		if l.hasHeader && rowNum == 1 {
			continue
		}

		// æ£€æŸ¥å†…å®¹åˆ—ç´¢å¼•
		if l.contentCol >= len(record) {
			log.Warnf("âš ï¸  Row %d: content_col %d out of range", rowNum, l.contentCol)
			continue
		}

		doc := models.Document{
			ID:      fmt.Sprintf("csv_row_%d", rowNum),
			Content: record[l.contentCol],
			Metadata: map[string]interface{}{
				"row": rowNum,
				"source": l.filePath,
			},
		}

		// æ·»åŠ å…ƒæ•°æ®åˆ—
		for i, colIdx := range l.metaCols {
			if colIdx < len(record) {
				key := fmt.Sprintf("meta_%d", i)
				doc.Metadata[key] = record[colIdx]
			}
		}

		docs = append(docs, doc)
	}

	log.Infof("âœ… Loaded %d documents from CSV", len(docs))
	return docs, nil
}

// RecipeLoader èœè°±æ•°æ®åŠ è½½å™¨ï¼ˆä¸“é—¨ç”¨äºæœ¬é¡¹ç›®ï¼‰
type RecipeLoader struct {
	filePath string
}

// Recipe èœè°±æ•°æ®ç»“æ„
type Recipe struct {
	Name        string   `json:"name"`
	Ingredients []string `json:"ingredients"`
	Steps       []string `json:"steps"`
	Category    string   `json:"category"`
	Cuisine     string   `json:"cuisine"`
	Tags        []string `json:"tags"`
}

// NewRecipeLoader åˆ›å»ºèœè°±åŠ è½½å™¨
func NewRecipeLoader(filePath string) *RecipeLoader {
	return &RecipeLoader{
		filePath: filePath,
	}
}

// Load åŠ è½½èœè°±æ•°æ®
func (l *RecipeLoader) Load(ctx context.Context) ([]models.Document, error) {
	log.Infof("ğŸ“– Loading recipes from: %s", l.filePath)

	file, err := os.Open(l.filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to open file: %w", err)
	}
	defer file.Close()

	var recipes []Recipe
	decoder := json.NewDecoder(file)
	if err := decoder.Decode(&recipes); err != nil {
		return nil, fmt.Errorf("failed to decode recipes: %w", err)
	}

	// è½¬æ¢ä¸ºæ–‡æ¡£
	docs := make([]models.Document, 0, len(recipes))
	for i, recipe := range recipes {
		// æ„å»ºå†…å®¹
		content := fmt.Sprintf("èœåï¼š%s\n\né£Ÿæï¼š\n%s\n\næ­¥éª¤ï¼š\n%s",
			recipe.Name,
			strings.Join(recipe.Ingredients, "\n"),
			strings.Join(recipe.Steps, "\n"))

		doc := models.Document{
			ID:      fmt.Sprintf("recipe_%d", i),
			Content: content,
			Metadata: map[string]interface{}{
				"name":        recipe.Name,
				"category":    recipe.Category,
				"cuisine":     recipe.Cuisine,
				"tags":        recipe.Tags,
				"ingredients": recipe.Ingredients,
				"type":        "recipe",
			},
		}

		docs = append(docs, doc)
	}

	log.Infof("âœ… Loaded %d recipes", len(recipes))
	return docs, nil
}

// generateDocID ç”Ÿæˆæ–‡æ¡£ID
func generateDocID(path string) string {
	// ç®€å•çš„IDç”Ÿæˆï¼šä½¿ç”¨æ–‡ä»¶è·¯å¾„çš„hash
	return fmt.Sprintf("doc_%x", len(path))
}
