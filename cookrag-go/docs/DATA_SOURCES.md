# æ•°æ®è·å–æŒ‡å— - å¤§æ‰¹é‡æ•°æ®å¯¼å…¥æ–¹æ¡ˆ

## ğŸ¯ æ¨èæ•°æ®é›†æ¥æº

### 1. ä¸­æ–‡èœè°±æ•°æ®é›†ï¼ˆæ¨èç”¨äºæœ¬é¡¹ç›®ï¼‰

#### é€‰é¡¹1: GitHubå¼€æºæ•°æ®é›†
```bash
# ä¸­æ–‡èœè°±æ•°æ®é›†
https://github.com/Andreas2021/Chinese-recipes-dataset

# èœè°±JSONæ•°æ®
https://github.com/richardzitran/chinese-cooking-recipes

# ç¾é£Ÿèœè°±å¤§å…¨
https://github.com/meilic/recipe-dataset
```

#### é€‰é¡¹2: Kaggleæ•°æ®é›†
```bash
# Recipe1M+ å¤§è§„æ¨¡èœè°±æ•°æ®é›†ï¼ˆ100ä¸‡+èœè°±ï¼‰
https://www.kaggle.com/datasets/paulmoise/predictions-of-chef-cooking-time

# Food.com èœè°±æ•°æ®é›†
https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions

# ä¸­æ–‡èœè°±æ•°æ®
https://www.kaggle.com/datasets (æœç´¢ "chinese recipes")
```

#### é€‰é¡¹3: Hugging Faceæ•°æ®é›†
```python
from datasets import load_dataset

# åŠ è½½èœè°±æ•°æ®é›†
dataset = load_dataset("recipe_nl", "recipes")
# æˆ–
dataset = load_dataset("food_dataloader")
```

### 2. é€šç”¨æ–‡æœ¬æ•°æ®é›†ï¼ˆç”¨äºæµ‹è¯•ï¼‰

#### ä¸­æ–‡æ–‡æœ¬æ•°æ®é›†
```bash
# Wikipediaä¸­æ–‡æ•°æ®
https://dumps.wikimedia.org/zhwiki/latest/

# ä¸­æ–‡é—®ç­”æ•°æ®é›†
https://github.com/chiLi0905/NLP-Chinese-DataSet

# ä¸­æ–‡æ–‡æœ¬åˆ†ç±»æ•°æ®é›†
https://github.com/sketu/jieba-wordline
```

#### è‹±æ–‡æ–‡æœ¬æ•°æ®é›†
```bash
# SQuADé—®ç­”æ•°æ®é›†
https://rajpurkar.github.io/SQuAD-explorer/

# MS MARCO
https://microsoft.github.io/msmarco/

# Wikipediaæ•°æ®
https://dumps.wikimedia.org/enwiki/latest/
```

### 3. çˆ¬è™«è·å–æ•°æ®

#### ä½¿ç”¨Pythonçˆ¬è™«
```python
import requests
from bs4 import BeautifulSoup
import json

# ç¤ºä¾‹ï¼šçˆ¬å–èœè°±ç½‘ç«™
def scrape_recipes(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    recipes = []
    # æå–èœè°±ä¿¡æ¯
    # ...

    return recipes

# ä¿å­˜ä¸ºJSON
with open('recipes.json', 'w', encoding='utf-8') as f:
    json.dump(recipes, f, ensure_ascii=False, indent=2)
```

#### æ¨èçˆ¬å–çš„ç½‘ç«™
- ä¸‹å¨æˆ¿ (https://www.xiachufang.com/)
- è±†æœç¾é£Ÿ (https://www.douguo.com/)
- ç¾é£Ÿæ° (https://www.meishij.net/)

## ğŸ“¥ æ•°æ®æ ¼å¼è½¬æ¢

### 1. ä»JSONè½¬æ¢
æˆ‘ä»¬å·²ç»æ”¯æŒJSONæ ¼å¼ï¼Œç¡®ä¿ä½ çš„æ•°æ®ç¬¦åˆä»¥ä¸‹æ ¼å¼ï¼š

```json
[
  {
    "name": "èœå",
    "category": "åˆ†ç±»",
    "cuisine": "èœç³»",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "ingredients": ["é£Ÿæ1", "é£Ÿæ2"],
    "steps": ["æ­¥éª¤1", "æ­¥éª¤2"]
  }
]
```

### 2. ä»CSVè½¬æ¢
```python
import pandas as pd
import json

# è¯»å–CSV
df = pd.read_csv('recipes.csv')

# è½¬æ¢ä¸ºJSONæ ¼å¼
recipes = []
for _, row in df.iterrows():
    recipe = {
        "name": row['èœå'],
        "category": row['åˆ†ç±»'],
        "cuisine": row['èœç³»'],
        "ingredients": row['é£Ÿæ'].split(','),
        "steps": row['æ­¥éª¤'].split('|')
    }
    recipes.append(recipe)

# ä¿å­˜ä¸ºJSON
with open('recipes.json', 'w', encoding='utf-8') as f:
    json.dump(recipes, f, ensure_ascii=False, indent=2)
```

### 3. ä»Markdownè½¬æ¢
```python
import json
import os
import re

def parse_markdown_recipes(md_file):
    recipes = []
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # è§£æMarkdownæ ¼å¼çš„èœè°±
    # æ ¹æ®å®é™…æ ¼å¼è°ƒæ•´è§£æé€»è¾‘
    # ...

    return recipes

# æ‰¹é‡è½¬æ¢
recipes = parse_markdown_recipes('èœè°±å¤§å…¨.md')
with open('recipes.json', 'w', encoding='utf-8') as f:
    json.dump(recipes, f, ensure_ascii=False, indent=2)
```

## ğŸš€ ä½¿ç”¨å¯¼å…¥å·¥å…·

### 1. åŸºç¡€å¯¼å…¥

```bash
# 1. å‡†å¤‡æ•°æ®æ–‡ä»¶
# å°†æ•°æ®æ–‡ä»¶æ”¾åœ¨ data/recipes/recipes.json

# 2. å¯åŠ¨ä¾èµ–æœåŠ¡
docker-compose -f deployments/docker/docker-compose.yml up -d

# 3. è¿è¡Œå¯¼å…¥ç¨‹åº
go run cmd/import/main.go
```

### 2. è‡ªå®šä¹‰å¯¼å…¥

åˆ›å»ºä½ è‡ªå·±çš„å¯¼å…¥è„šæœ¬ï¼š

```go
package main

import (
    "context"
    "log"
    "cookrag-go/pkg/data"
    "cookrag-go/internal/config"
    "cookrag-go/pkg/ml/embedding"
    "cookrag-go/pkg/storage/milvus"
)

func main() {
    // åŠ è½½é…ç½®
    cfg, _ := config.Load("config/config.yaml")

    // åˆå§‹åŒ–
    embeddingProvider, _ := embedding.NewProvider(cfg.Embedding)
    milvusClient, _ := milvus.NewClient(cfg.Milvus.Host, cfg.Milvus.Port)

    // åˆ›å»ºç´¢å¼•å™¨
    indexer := data.NewIndexer(embeddingProvider, milvusClient, nil)

    // åŠ è½½ä½ çš„æ•°æ®
    loader := data.NewJSONLoader("path/to/your/data.json")
    docs, _ := loader.Load(context.Background())

    // ç´¢å¼•
    config := &data.IndexConfig{
        CollectionName: "my_collection",
        VectorIndex: true,
        BM25Index: true,
        BatchSize: 100,
    }

    indexer.IndexDocuments(context.Background(), docs, config)
}
```

## ğŸ“Š æ•°æ®é‡å»ºè®®

### æµ‹è¯•ç¯å¢ƒ
- **æ–‡æ¡£æ•°**: 100-1,000ç¯‡
- **ç”¨é€”**: åŠŸèƒ½æµ‹è¯•ã€å¼€å‘è°ƒè¯•
- **å¯¼å…¥æ—¶é—´**: 2-10åˆ†é’Ÿ

### æ¼”ç¤ºç¯å¢ƒ
- **æ–‡æ¡£æ•°**: 1,000-10,000ç¯‡
- **ç”¨é€”**: é¢è¯•æ¼”ç¤ºã€POC
- **å¯¼å…¥æ—¶é—´**: 10-60åˆ†é’Ÿ

### ç”Ÿäº§ç¯å¢ƒ
- **æ–‡æ¡£æ•°**: 100,000+ç¯‡
- **ç”¨é€”**: å®é™…åº”ç”¨
- **å¯¼å…¥æ—¶é—´**: 1å°æ—¶+ï¼ˆéœ€è¦ä¼˜åŒ–ï¼‰

## ğŸ¯ æ¨èçš„æ•°æ®é›†

### å¿«é€Ÿå¼€å§‹ï¼ˆå†…ç½®æ•°æ®ï¼‰
```bash
# é¡¹ç›®å·²åŒ…å«10ä¸ªç¤ºä¾‹èœè°±
go run cmd/import/main.go
```

### å°å‹æ•°æ®é›†ï¼ˆ100-500ä¸ªèœè°±ï¼‰
```bash
# ä¸‹è½½æ•°æ®é›†
cd data/recipes
wget https://raw.githubusercontent.com/Andreas2021/Chinese-recipes-dataset/main/recipes.json

# å¯¼å…¥
go run cmd/import/main.go
```

### ä¸­å‹æ•°æ®é›†ï¼ˆ1000-5000ä¸ªèœè°±ï¼‰
```bash
# ä»Kaggleä¸‹è½½
# 1. è®¿é—® https://www.kaggle.com/datasets
# 2. æœç´¢ "chinese recipes"
# 3. ä¸‹è½½æ•°æ®é›†
# 4. è½¬æ¢ä¸ºJSONæ ¼å¼
# 5. å¯¼å…¥
```

### å¤§å‹æ•°æ®é›†ï¼ˆ10,000+èœè°±ï¼‰
```bash
# Recipe1M+ æ•°æ®é›†
https://www.kaggle.com/datasets/paulmoise/predictions-of-chef-cooking-time

# æ‰¹é‡å¯¼å…¥ï¼ˆéœ€è¦ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°ï¼‰
go run cmd/import/main.go --batch-size 1000
```

## ğŸ”§ æ•°æ®é¢„å¤„ç†

### 1. æ•°æ®æ¸…æ´—
```python
import json
import re

def clean_text(text):
    # å»é™¤å¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)
    # å»é™¤ç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
    return text.strip()

# æ¸…æ´—æ•°æ®
with open('raw_recipes.json', 'r', encoding='utf-8') as f:
    recipes = json.load(f)

for recipe in recipes:
    recipe['name'] = clean_text(recipe['name'])
    recipe['steps'] = [clean_text(step) for step in recipe['steps']]

with open('cleaned_recipes.json', 'w', encoding='utf-8') as f:
    json.dump(recipes, f, ensure_ascii=False, indent=2)
```

### 2. æ•°æ®å¢å¼ºï¼ˆå¯é€‰ï¼‰
```python
# ä¸ºèœè°±æ·»åŠ æ›´å¤šå…ƒæ•°æ®
for recipe in recipes:
    # æ·»åŠ éš¾åº¦ç­‰çº§
    if len(recipe['steps']) > 5:
        recipe['difficulty'] = 'å›°éš¾'
    elif len(recipe['steps']) > 3:
        recipe['difficulty'] = 'ä¸­ç­‰'
    else:
        recipe['difficulty'] = 'ç®€å•'

    # æ·»åŠ æ—¶é—´ä¼°ç®—
    recipe['time_estimate'] = len(recipe['steps']) * 5  # åˆ†é’Ÿ
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–
```go
// è°ƒæ•´æ‰¹é‡å¤§å°
config := &data.IndexConfig{
    BatchSize: 100,  // æ ¹æ®APIé™åˆ¶è°ƒæ•´
}
```

### 2. å¹¶å‘å¤„ç†
```go
// ä½¿ç”¨goroutineå¹¶å‘å¤„ç†
func batchProcess(docs []models.Document, batchSize int) {
    for i := 0; i < len(docs); i += batchSize {
        end := i + batchSize
        if end > len(docs) {
            end = len(docs)
        }
        batch := docs[i:end]

        // å¹¶å‘å¤„ç†
        go processBatch(batch)
    }
}
```

### 3. é”™è¯¯å¤„ç†å’Œé‡è¯•
```go
// æ·»åŠ é‡è¯•æœºåˆ¶
for retry := 0; retry < 3; retry++ {
    err := indexer.IndexDocuments(ctx, docs, config)
    if err == nil {
        break
    }
    log.Warnf("Retry %d: %v", retry+1, err)
    time.Sleep(time.Second * time.Duration(retry+1))
}
```

## ğŸ‰ æ€»ç»“

**å¿«é€Ÿå¼€å§‹**ï¼š
```bash
# 1. å†…ç½®æ•°æ®ï¼ˆ10ä¸ªèœè°±ï¼‰
go run cmd/import/main.go

# 2. ä¸‹è½½æ›´å¤šæ•°æ®
# è®¿é—®æ¨èçš„æ•°æ®æºç½‘ç«™
# ä¸‹è½½æ•°æ®å¹¶è½¬æ¢ä¸ºJSONæ ¼å¼
# æ”¾åˆ° data/recipes/ ç›®å½•

# 3. é‡æ–°å¯¼å…¥
go run cmd/import/main.go
```

**æ¨èæ•°æ®æº**ï¼š
1. GitHubå¼€æºæ•°æ®é›†ï¼ˆå…è´¹ã€æ˜“è·å–ï¼‰
2. Kaggleæ•°æ®é›†ï¼ˆé«˜è´¨é‡ã€æœ‰æ ‡æ³¨ï¼‰
3. Hugging Faceï¼ˆæ ¼å¼æ ‡å‡†ã€æ˜“äºä½¿ç”¨ï¼‰
4. è‡ªè¡Œçˆ¬å–ï¼ˆå®šåˆ¶åŒ–ã€ç¬¦åˆéœ€æ±‚ï¼‰

ç°åœ¨ä½ å¯ä»¥è½»æ¾è·å–å¤§é‡æ•°æ®æ¥æµ‹è¯•ä½ çš„RAGç³»ç»Ÿäº†ï¼ğŸš€
