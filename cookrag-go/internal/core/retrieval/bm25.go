package retrieval

import (
	"context"
	"fmt"
	"math"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/charmbracelet/log"
	"cookrag-go/internal/models"
	"cookrag-go/internal/observability"
	"github.com/yanyiwu/gojieba"
)

// BM25Config BM25é…ç½®å‚æ•°
type BM25Config struct {
	K1 float64 // è¯é¢‘é¥±å’Œå‚æ•° (é€šå¸¸1.2-2.0)
	B  float64 // é•¿åº¦æƒ©ç½šå‚æ•° (é€šå¸¸0.75)
}

// DefaultBM25Config é»˜è®¤BM25é…ç½®
func DefaultBM25Config() *BM25Config {
	return &BM25Config{
		K1: 1.5,
		B:  0.75,
	}
}

// InvertedIndex å€’æŽ’ç´¢å¼•
type InvertedIndex struct {
	mu       sync.RWMutex
	// è¯é¡¹ -> æ–‡æ¡£IDåˆ—è¡¨
	Postings map[string][]int64
	// è¯é¡¹ -> æ–‡æ¡£é¢‘çŽ‡
	DocFreq map[string]int
	// æ–‡æ¡£ID -> æ–‡æ¡£é•¿åº¦
	DocLengths map[int64]int
	// å¹³å‡æ–‡æ¡£é•¿åº¦
	AvgDocLength float64
	// æ€»æ–‡æ¡£æ•°
	TotalDocs int
}

// BM25Retriever BM25æ£€ç´¢å™¨
type BM25Retriever struct {
	config    *BM25Config
	index     *InvertedIndex
	tokenizer *gojieba.Jieba
}

// NewBM25Retriever åˆ›å»ºBM25æ£€ç´¢å™¨
func NewBM25Retriever(config *BM25Config) *BM25Retriever {
	if config == nil {
		config = DefaultBM25Config()
	}

	// åˆå§‹åŒ– jieba åˆ†è¯å™¨
	tokenizer := gojieba.NewJieba()

	return &BM25Retriever{
		config:    config,
		tokenizer: tokenizer,
		index: &InvertedIndex{
			Postings:     make(map[string][]int64),
			DocFreq:      make(map[string]int),
			DocLengths:   make(map[int64]int),
			AvgDocLength: 0,
			TotalDocs:    0,
		},
	}
}

// Tokenize ä½¿ç”¨ jieba è¿›è¡Œä¸­æ–‡åˆ†è¯
func (r *BM25Retriever) Tokenize(text string) []string {
	// ä½¿ç”¨ jieba åˆ†è¯ï¼Œæœç´¢æ¨¡å¼ (HMM=true)
	words := r.tokenizer.Cut(text, true)

	// åœç”¨è¯è¿‡æ»¤ï¼ˆç®€åŒ–ç‰ˆï¼‰
	stopWords := map[string]bool{
		"çš„": true, "äº†": true, "åœ¨": true, "æ˜¯": true, "æˆ‘": true,
		"æœ‰": true, "å’Œ": true, "å°±": true, "ä¸": true, "äºº": true,
		"ä¹‹": true, "ä¸Ž": true, "åŠ": true, "ç­‰": true, "æˆ–": true,
		"å—": true, "å‘¢": true, "å§": true, "å•Š": true, "å‘€": true,
		// è‹±æ–‡åœç”¨è¯
		"the": true, "a": true, "an": true, "and": true, "or": true,
		"but": true, "in": true, "on": true, "at": true, "to": true,
		"of": true, "for": true, "with": true, "by": true, "from": true,
	}

	filtered := make([]string, 0)
	for _, word := range words {
		word = strings.TrimSpace(word)
		// è¿‡æ»¤åœç”¨è¯ã€å•å­—ç¬¦ã€çº¯æ•°å­—/æ ‡ç‚¹
		if word != "" && !stopWords[word] && len(word) > 1 && !isPunctuation(word) {
			filtered = append(filtered, word)
		}
	}

	return filtered
}

// isPunctuation åˆ¤æ–­æ˜¯å¦æ˜¯æ ‡ç‚¹ç¬¦å·
// åªæœ‰æ•´ä¸ªå­—ç¬¦ä¸²éƒ½æ˜¯æ ‡ç‚¹ç¬¦å·æ‰è¿”å›žtrueï¼Œåªè¦æœ‰ä¸€ä¸ªæœ‰æ•ˆå­—ç¬¦å°±ä¿ç•™
func isPunctuation(s string) bool {
	if len(s) == 0 {
		return true
	}

	hasValidChar := false
	for _, r := range s {
		isAlpha := (r >= 'a' && r <= 'z') || (r >= 'A' && r <= 'Z')
		isDigit := r >= '0' && r <= '9'
		isChinese := r >= 0x4e00 && r <= 0x9fa5

		if isAlpha || isDigit || isChinese {
			hasValidChar = true
		}
	}

	return !hasValidChar // æ²¡æœ‰ä»»ä½•æœ‰æ•ˆå­—ç¬¦æ‰ç®—æ ‡ç‚¹
}

// IndexDocuments ç´¢å¼•æ–‡æ¡£
func (r *BM25Retriever) IndexDocuments(ctx context.Context, documents []models.Document) error {
	log.Infof("ðŸ“ Indexing %d documents with BM25", len(documents))

	r.index.mu.Lock()
	defer r.index.mu.Unlock()

	totalLength := 0 // ç´¯è®¡æ‰€æœ‰æ–‡æ¡£çš„æ€»è¯æ•°ï¼ˆç”¨äºŽè®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦ï¼‰

	for _, doc := range documents {
		docID := doc.ID
		if docID == "" {
			docID = fmt.Sprintf("doc_%d", r.index.TotalDocs)
		}

		// åˆ†è¯
		words := r.Tokenize(doc.Content)
		docLength := len(words) // å½“å‰æ–‡æ¡£çš„è¯æ•°
		docIDInt := int64(r.index.TotalDocs) // TotalDocs å½“å‰å€¼å°±æ˜¯å½“å‰æ–‡æ¡£çš„IDï¼ˆ0, 1, 2...ï¼‰
		r.index.DocLengths[docIDInt] = docLength
		totalLength += docLength // ç´¯åŠ æ€»è¯æ•°ï¼šä¾‹ï¼šæ–‡æ¡£0æœ‰50è¯ï¼Œæ–‡æ¡£1æœ‰30è¯ â†’ totalLength=80

		// æž„å»ºå€’æŽ’ç´¢å¼•ï¼ˆè¯ â†’ æ–‡æ¡£åˆ—è¡¨ çš„æ˜ å°„ï¼‰
		// ä¾‹ï¼š{"çº¢çƒ§": [0, 5, 12], "è‚‰": [0, 5, 12, 23]} è¡¨ç¤ºè¿™äº›è¯å‡ºçŽ°åœ¨å“ªäº›æ–‡æ¡£ä¸­
		termFreq := make(map[string]int) // ç»Ÿè®¡å½“å‰æ–‡æ¡£ä¸­æ¯ä¸ªè¯çš„å‡ºçŽ°æ¬¡æ•°
		for _, word := range words {
			termFreq[word]++ // ä¾‹ï¼š{"çº¢çƒ§": 2, "è‚‰": 3, "æ€Žä¹ˆ": 1, "åš": 1}
		}

		// æ›´æ–°å€’æŽ’è¡¨ï¼ˆè®°å½•æ¯ä¸ªè¯å‡ºçŽ°åœ¨å“ªäº›æ–‡æ¡£ä¸­ï¼‰
		for term := range termFreq { // éåŽ†å½“å‰æ–‡æ¡£ä¸­çš„æ¯ä¸ªå”¯ä¸€è¯
			if _, exists := r.index.Postings[term]; !exists {
				r.index.Postings[term] = make([]int64, 0) // åˆå§‹åŒ–è¯¥è¯çš„æ–‡æ¡£åˆ—è¡¨
			}
			// å°†å½“å‰æ–‡æ¡£IDæ·»åŠ åˆ°è¯¥è¯çš„å€’æŽ’åˆ—è¡¨
			// TotalDocs ä½œä¸ºè®¡æ•°å™¨ï¼šå¤„ç†æ–‡æ¡£0æ—¶æ˜¯0ï¼Œå¤„ç†å®ŒåŽ++å˜æˆ1ï¼ˆä¸‹ä¸€ä¸ªæ–‡æ¡£çš„IDï¼‰
			r.index.Postings[term] = append(r.index.Postings[term], int64(r.index.TotalDocs))
		}

		r.index.TotalDocs++ // å¤„ç†å®Œå½“å‰æ–‡æ¡£åŽé€’å¢žï¼Œä¸ºä¸‹ä¸€ä¸ªæ–‡æ¡£å‡†å¤‡ID
	}

	// è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦ï¼ˆBM25ç®—æ³•éœ€è¦ï¼‰
	// totalLength: æ‰€æœ‰æ–‡æ¡£çš„æ€»è¯æ•°ï¼ˆä¾‹ï¼š3000è¯ï¼‰
	// r.index.TotalDocs: æ–‡æ¡£æ€»æ•°ï¼ˆä¾‹ï¼š10ä¸ªæ–‡æ¡£ï¼‰
	// r.index.AvgDocLength: å¹³å‡æ¯ä¸ªæ–‡æ¡£çš„è¯æ•°ï¼ˆä¾‹ï¼š3000/10=300è¯ï¼‰
	if r.index.TotalDocs > 0 {
		r.index.AvgDocLength = float64(totalLength) / float64(r.index.TotalDocs)
	}

	// è®¡ç®—æ–‡æ¡£é¢‘çŽ‡ï¼ˆDF: Document Frequencyï¼Œå³ä¸€ä¸ªè¯å‡ºçŽ°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­ï¼‰
	// ç”¨äºŽè®¡ç®—IDFï¼ˆé€†æ–‡æ¡£é¢‘çŽ‡ï¼‰ï¼šDFè¶Šå°ï¼ˆè¯è¶Šç¨€æœ‰ï¼‰ï¼ŒIDFè¶Šå¤§ï¼Œæƒé‡è¶Šé«˜
	for term, postings := range r.index.Postings {
		uniqueDocs := make(map[int64]bool) // ç”¨mapåŽ»é‡ï¼ˆç¡®ä¿åŒä¸€æ–‡æ¡£åªè®¡æ•°ä¸€æ¬¡ï¼‰
		for _, docID := range postings {
			uniqueDocs[docID] = true
		}
		r.index.DocFreq[term] = len(uniqueDocs) // ä¾‹ï¼šPostings["çº¢çƒ§"]=[0,1,2] â†’ DF=3
	}

	log.Infof("âœ… BM25 indexing completed: %d docs, avg_len: %.2f, %d unique terms",
		r.index.TotalDocs, r.index.AvgDocLength, len(r.index.Postings))

	return nil
}

// Retrieve BM25æ£€ç´¢
func (r *BM25Retriever) Retrieve(ctx context.Context, query string, topK int) ([]models.Document, error) {
	// åˆ›å»ºé“¾è·¯è¿½è¸ª span
	span := observability.GlobalTracer.StartSpan(ctx, "bm25_retrieve", map[string]interface{}{
		"query": query,
		"top_k": topK,
	})
	defer span.End()

	startTime := time.Now()

	// åˆ†è¯
	queryTerms := r.Tokenize(query)
	if len(queryTerms) == 0 {
		return []models.Document{}, nil
	}

	log.Infof("ðŸ” BM25 retrieval: query='%s', terms=%d, top_k=%d", query, len(queryTerms), topK)
	span.AddMetadata("term_count", len(queryTerms))

	r.index.mu.RLock()
	defer r.index.mu.RUnlock()

	// è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„BM25åˆ†æ•°
	scores := make(map[int64]float64)

	for _, term := range queryTerms { // éåŽ†æŸ¥è¯¢ä¸­çš„æ¯ä¸ªè¯ï¼ˆå¦‚ï¼š["çº¢çƒ§", "è‚‰"]ï¼‰
		postings, termExists := r.index.Postings[term] // èŽ·å–åŒ…å«è¯¥è¯çš„æ–‡æ¡£åˆ—è¡¨
		if !termExists {
			continue // è¯ä¸åœ¨ç´¢å¼•ä¸­ï¼Œè·³è¿‡
		}

		docFreq := r.index.DocFreq[term] // è¯¥è¯çš„æ–‡æ¡£é¢‘çŽ‡ï¼ˆå‡ºçŽ°åœ¨å¤šå°‘ä¸ªæ–‡æ¡£ä¸­ï¼‰
		// è®¡ç®—IDFï¼ˆé€†æ–‡æ¡£é¢‘çŽ‡ï¼‰ï¼šè¯è¶Šç¨€æœ‰ï¼ŒIDFè¶Šå¤§
		// å…¬å¼ï¼šlog((æ€»æ–‡æ¡£æ•° - æ–‡æ¡£é¢‘çŽ‡ + 0.5) / (æ–‡æ¡£é¢‘çŽ‡ + 0.5))
		idf := math.Log((float64(r.index.TotalDocs) - float64(docFreq) + 0.5) / (float64(docFreq) + 0.5))

		// è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„åˆ†æ•°è´¡çŒ®
		for _, docID := range postings { // éåŽ†åŒ…å«è¯¥è¯çš„æ‰€æœ‰æ–‡æ¡£
			docLength := r.index.DocLengths[docID] // è¯¥æ–‡æ¡£çš„è¯æ•°
			// å½’ä¸€åŒ–å› å­ï¼šé•¿æ–‡æ¡£ä¼š"æƒ©ç½š"åˆ†æ•°ï¼ˆé¿å…é•¿æ–‡æ¡£å ä¼˜åŠ¿ï¼‰
			// B=0.75: å¦‚æžœæ–‡æ¡£é•¿åº¦æ˜¯å¹³å‡é•¿åº¦çš„2å€ï¼Œå› å­è¶Šå¤§ï¼Œåˆ†æ•°è¶Šä½Ž
			normFactor := 1 - r.config.B + r.config.B*float64(docLength)/r.index.AvgDocLength

			// ç®€åŒ–ç‰ˆï¼šä½¿ç”¨è¯é¢‘=1ï¼ˆå®žé™…åº”è¯¥ç»Ÿè®¡è¯åœ¨è¯¥æ–‡æ¡£ä¸­å‡ºçŽ°çš„æ¬¡æ•°ï¼‰
			tf := 1.0
			// BM25æ ¸å¿ƒå…¬å¼ï¼šIDF Ã— (TF Ã— (K1 + 1)) / (TF + K1 Ã— å½’ä¸€åŒ–å› å­)
			// K1=1.5: æŽ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼ˆTFå†å¤§ï¼Œåˆ†æ•°ä¹Ÿä¸ä¼šæ— é™å¢žé•¿ï¼‰
			score := idf * (tf * (r.config.K1 + 1)) / (tf + r.config.K1*normFactor)

			scores[docID] += score // ç´¯åŠ è¯¥è¯å¯¹æ–‡æ¡£çš„åˆ†æ•°è´¡çŒ®
		}
	}

	// æŽ’åº
	type docScore struct {
		DocID int64
		Score float64
	}

	rankedDocs := make([]docScore, 0, len(scores))
	for docID, score := range scores {
		rankedDocs = append(rankedDocs, docScore{docID, score})
	}

	sort.Slice(rankedDocs, func(i, j int) bool {
		return rankedDocs[i].Score > rankedDocs[j].Score
	})

	// è¿”å›žtop-kç»“æžœ
	results := make([]models.Document, 0, min(topK, len(rankedDocs)))
	for i := 0; i < min(topK, len(rankedDocs)); i++ {
		results = append(results, models.Document{
			ID:    fmt.Sprintf("doc_%d", rankedDocs[i].DocID),
			Score: float32(rankedDocs[i].Score),
		})
	}

	latency := time.Since(startTime).Milliseconds()
	span.AddMetadata("result_count", len(results))
	span.AddMetadata("latency_ms", float64(latency))
	log.Infof("âœ… BM25 retrieval completed: %d results in %dms", len(results), latency)

	return results, nil
}

// GetStats èŽ·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
func (r *BM25Retriever) GetStats() map[string]interface{} {
	r.index.mu.RLock()
	defer r.index.mu.RUnlock()

	return map[string]interface{}{
		"total_docs":      r.index.TotalDocs,
		"unique_terms":    len(r.index.Postings),
		"avg_doc_length":  r.index.AvgDocLength,
		"k1":              r.config.K1,
		"b":               r.config.B,
	}
}
