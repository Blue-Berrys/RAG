package retrieval

import (
	"context"
	"fmt"
	"math"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/charmbracelet/log"
	"cookrag-go/internal/models"
)

// BM25Config BM25é…ç½®å‚æ•°
type BM25Config struct {
	K1 float64 // è¯é¢‘é¥±å’Œå‚æ•° (é€šå¸¸1.2-2.0)
	B  float64 // é•¿åº¦æƒ©ç½šå‚æ•° (é€šå¸¸0.75)
}

// DefaultBM25Config é»˜è®¤BM25é…ç½®
func DefaultBM25Config() *BM25Config {
	return &BM25Config{
		K1: 1.5,
		B:  0.75,
	}
}

// InvertedIndex å€’æŽ’ç´¢å¼•
type InvertedIndex struct {
	mu       sync.RWMutex
	// è¯é¡¹ -> æ–‡æ¡£IDåˆ—è¡¨
	Postings map[string][]int64
	// è¯é¡¹ -> æ–‡æ¡£é¢‘çŽ‡
	DocFreq map[string]int
	// æ–‡æ¡£ID -> æ–‡æ¡£é•¿åº¦
	DocLengths map[int64]int
	// å¹³å‡æ–‡æ¡£é•¿åº¦
	AvgDocLength float64
	// æ€»æ–‡æ¡£æ•°
	TotalDocs int
}

// BM25Retriever BM25æ£€ç´¢å™¨
type BM25Retriever struct {
	config *BM25Config
	index  *InvertedIndex
}

// NewBM25Retriever åˆ›å»ºBM25æ£€ç´¢å™¨
func NewBM25Retriever(config *BM25Config) *BM25Retriever {
	if config == nil {
		config = DefaultBM25Config()
	}

	return &BM25Retriever{
		config: config,
		index: &InvertedIndex{
			Postings:    make(map[string][]int64),
			DocFreq:     make(map[string]int),
			DocLengths:  make(map[int64]int),
			AvgDocLength: 0,
			TotalDocs:   0,
		},
	}
}

// Tokenize åˆ†è¯ï¼ˆç®€å•å®žçŽ°ï¼Œå¯æ›¿æ¢ä¸ºjiebaç­‰ä¸­æ–‡åˆ†è¯ï¼‰
func (r *BM25Retriever) Tokenize(text string) []string {
	// è½¬å°å†™
	text = strings.ToLower(text)
	// ç®€å•åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
	words := strings.FieldsFunc(text, func(c rune) bool {
		return c == ' ' || c == '\t' || c == '\n' || c == '.' || c == ',' || c == '!' || c == '?'
	})

	// åœç”¨è¯è¿‡æ»¤ï¼ˆç®€åŒ–ç‰ˆï¼‰
	stopWords := map[string]bool{
		"çš„": true, "äº†": true, "åœ¨": true, "æ˜¯": true, "æˆ‘": true,
		"æœ‰": true, "å’Œ": true, "å°±": true, "ä¸": true, "äºº": true,
		"the": true, "a": true, "an": true, "and": true, "or": true,
		"but": true, "in": true, "on": true, "at": true, "to": true,
	}

	filtered := make([]string, 0)
	for _, word := range words {
		word = strings.TrimSpace(word)
		if word != "" && !stopWords[word] && len(word) > 1 {
			filtered = append(filtered, word)
		}
	}

	return filtered
}

// IndexDocuments ç´¢å¼•æ–‡æ¡£
func (r *BM25Retriever) IndexDocuments(ctx context.Context, documents []models.Document) error {
	log.Infof("ðŸ“ Indexing %d documents with BM25", len(documents))

	r.index.mu.Lock()
	defer r.index.mu.Unlock()

	totalLength := 0

	for _, doc := range documents {
		docID := doc.ID
		if docID == "" {
			docID = fmt.Sprintf("doc_%d", r.index.TotalDocs)
		}

		// åˆ†è¯
		words := r.Tokenize(doc.Content)
		docLength := len(words)
		docIDInt := int64(r.index.TotalDocs)
		r.index.DocLengths[docIDInt] = docLength
		totalLength += docLength

		// æž„å»ºå€’æŽ’ç´¢å¼•
		termFreq := make(map[string]int)
		for _, word := range words {
			termFreq[word]++
		}

		// æ›´æ–°å€’æŽ’è¡¨
		for term := range termFreq {
			if _, exists := r.index.Postings[term]; !exists {
				r.index.Postings[term] = make([]int64, 0)
			}
			r.index.Postings[term] = append(r.index.Postings[term], int64(r.index.TotalDocs))
		}

		r.index.TotalDocs++
	}

	// è®¡ç®—å¹³å‡æ–‡æ¡£é•¿åº¦
	if r.index.TotalDocs > 0 {
		r.index.AvgDocLength = float64(totalLength) / float64(r.index.TotalDocs)
	}

	// è®¡ç®—æ–‡æ¡£é¢‘çŽ‡
	for term, postings := range r.index.Postings {
		uniqueDocs := make(map[int64]bool)
		for _, docID := range postings {
			uniqueDocs[docID] = true
		}
		r.index.DocFreq[term] = len(uniqueDocs)
	}

	log.Infof("âœ… BM25 indexing completed: %d docs, avg_len: %.2f, %d unique terms",
		r.index.TotalDocs, r.index.AvgDocLength, len(r.index.Postings))

	return nil
}

// Retrieve BM25æ£€ç´¢
func (r *BM25Retriever) Retrieve(ctx context.Context, query string, topK int) ([]models.Document, error) {
	startTime := time.Now()

	// åˆ†è¯
	queryTerms := r.Tokenize(query)
	if len(queryTerms) == 0 {
		return []models.Document{}, nil
	}

	log.Infof("ðŸ” BM25 retrieval: query='%s', terms=%d, top_k=%d", query, len(queryTerms), topK)

	r.index.mu.RLock()
	defer r.index.mu.RUnlock()

	// è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„BM25åˆ†æ•°
	scores := make(map[int64]float64)

	for _, term := range queryTerms {
		postings, termExists := r.index.Postings[term]
		if !termExists {
			continue
		}

		docFreq := r.index.DocFreq[term]
		idf := math.Log((float64(r.index.TotalDocs) - float64(docFreq) + 0.5) / (float64(docFreq) + 0.5))

		// è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„åˆ†æ•°è´¡çŒ®
		for _, docID := range postings {
			docLength := r.index.DocLengths[docID]
			normFactor := 1 - r.config.B + r.config.B*float64(docLength)/r.index.AvgDocLength

			// ç®€åŒ–ç‰ˆï¼šä½¿ç”¨è¯é¢‘=1ï¼ˆå®žé™…åº”è¯¥ç»Ÿè®¡è¯é¢‘ï¼‰
			tf := 1.0
			score := idf * (tf * (r.config.K1 + 1)) / (tf + r.config.K1*normFactor)

			scores[docID] += score
		}
	}

	// æŽ’åº
	type docScore struct {
		DocID int64
		Score float64
	}

	rankedDocs := make([]docScore, 0, len(scores))
	for docID, score := range scores {
		rankedDocs = append(rankedDocs, docScore{docID, score})
	}

	sort.Slice(rankedDocs, func(i, j int) bool {
		return rankedDocs[i].Score > rankedDocs[j].Score
	})

	// è¿”å›žtop-kç»“æžœ
	results := make([]models.Document, 0, min(topK, len(rankedDocs)))
	for i := 0; i < min(topK, len(rankedDocs)); i++ {
		results = append(results, models.Document{
			ID:    fmt.Sprintf("doc_%d", rankedDocs[i].DocID),
			Score: float32(rankedDocs[i].Score),
		})
	}

	latency := time.Since(startTime).Milliseconds()
	log.Infof("âœ… BM25 retrieval completed: %d results in %dms", len(results), latency)

	return results, nil
}

// GetStats èŽ·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
func (r *BM25Retriever) GetStats() map[string]interface{} {
	r.index.mu.RLock()
	defer r.index.mu.RUnlock()

	return map[string]interface{}{
		"total_docs":      r.index.TotalDocs,
		"unique_terms":    len(r.index.Postings),
		"avg_doc_length":  r.index.AvgDocLength,
		"k1":              r.config.K1,
		"b":               r.config.B,
	}
}
