package observability

import (
	"context"
	"sync"
	"time"

	"github.com/charmbracelet/log"
)

// Metrics ç›‘æ§æŒ‡æ ‡
type Metrics struct {
	mu              sync.RWMutex
	QueryCount      int64         `json:"query_count"`
	TotalLatency    time.Duration `json:"total_latency_ms"`
	ErrorCount      int64         `json:"error_count"`
	CacheHitCount   int64         `json:"cache_hit_count"`
	CacheMissCount  int64         `json:"cache_miss_count"`
	VectorRetrievalCount int64    `json:"vector_retrieval_count"`
	BM25RetrievalCount   int64    `json:"bm25_retrieval_count"`
	GraphRetrievalCount  int64    `json:"graph_retrieval_count"`
	HybridRetrievalCount int64    `json:"hybrid_retrieval_count"`
}

// MetricsCollector æŒ‡æ ‡æ”¶é›†å™¨
type MetricsCollector struct {
	mu          sync.RWMutex
	metrics     *Metrics
	startTime   time.Time
}

// NewMetricsCollector åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
func NewMetricsCollector() *MetricsCollector {
	return &MetricsCollector{
		metrics: &Metrics{},
		startTime: time.Now(),
	}
}

// RecordQuery è®°å½•æŸ¥è¯¢
func (m *MetricsCollector) RecordQuery(latency time.Duration, strategy string) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.metrics.QueryCount++
	m.metrics.TotalLatency += latency

	switch strategy {
	case "vector":
		m.metrics.VectorRetrievalCount++
	case "bm25":
		m.metrics.BM25RetrievalCount++
	case "graph":
		m.metrics.GraphRetrievalCount++
	case "hybrid":
		m.metrics.HybridRetrievalCount++
	}
}

// RecordError è®°å½•é”™è¯¯
func (m *MetricsCollector) RecordError() {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.metrics.ErrorCount++
}

// RecordCacheHit è®°å½•ç¼“å­˜å‘½ä¸­
func (m *MetricsCollector) RecordCacheHit() {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.metrics.CacheHitCount++
}

// RecordCacheMiss è®°å½•ç¼“å­˜æœªå‘½ä¸­
func (m *MetricsCollector) RecordCacheMiss() {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.metrics.CacheMissCount++
}

// GetMetrics è·å–æŒ‡æ ‡
func (m *MetricsCollector) GetMetrics() *Metrics {
	m.mu.RLock()
	defer m.mu.RUnlock()

	return m.metrics
}

// GetAverageLatency è·å–å¹³å‡å»¶è¿Ÿ
func (m *MetricsCollector) GetAverageLatency() time.Duration {
	m.mu.RLock()
	defer m.mu.RUnlock()

	if m.metrics.QueryCount == 0 {
		return 0
	}

	return m.metrics.TotalLatency / time.Duration(m.metrics.QueryCount)
}

// GetCacheHitRate è·å–ç¼“å­˜å‘½ä¸­ç‡
func (m *MetricsCollector) GetCacheHitRate() float64 {
	m.mu.RLock()
	defer m.mu.RUnlock()

	total := m.metrics.CacheHitCount + m.metrics.CacheMissCount
	if total == 0 {
		return 0
	}

	return float64(m.metrics.CacheHitCount) / float64(total)
}

// GetErrorRate è·å–é”™è¯¯ç‡
func (m *MetricsCollector) GetErrorRate() float64 {
	m.mu.RLock()
	defer m.mu.RUnlock()

	if m.metrics.QueryCount == 0 {
		return 0
	}

	return float64(m.metrics.ErrorCount) / float64(m.metrics.QueryCount)
}

// GetUptime è·å–è¿è¡Œæ—¶é—´
func (m *MetricsCollector) GetUptime() time.Duration {
	return time.Since(m.startTime)
}

// LogMetrics æ—¥å¿—è®°å½•æŒ‡æ ‡
func (m *MetricsCollector) LogMetrics() {
	metrics := m.GetMetrics()

	log.Infof("ğŸ“Š Metrics Summary:")
	log.Infof("  Uptime: %s", m.GetUptime().Round(time.Second))
	log.Infof("  Total Queries: %d", metrics.QueryCount)
	log.Infof("  Average Latency: %dms", m.GetAverageLatency().Milliseconds())
	log.Infof("  Error Rate: %.2f%%", m.GetErrorRate()*100)
	log.Infof("  Cache Hit Rate: %.2f%%", m.GetCacheHitRate()*100)
	log.Infof("  Strategy Distribution:")
	log.Infof("    Vector: %d", metrics.VectorRetrievalCount)
	log.Infof("    BM25: %d", metrics.BM25RetrievalCount)
	log.Infof("    Graph: %d", metrics.GraphRetrievalCount)
	log.Infof("    Hybrid: %d", metrics.HybridRetrievalCount)
}

// StartMetricsReporter å¯åŠ¨æŒ‡æ ‡æŠ¥å‘Š
func (m *MetricsCollector) StartMetricsReporter(ctx context.Context, interval time.Duration) {
	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			log.Info("ğŸ›‘ Metrics reporter stopped")
			return
		case <-ticker.C:
			m.LogMetrics()
		}
	}
}

// Global global metrics collector
var Global *MetricsCollector

func init() {
	Global = NewMetricsCollector()
}
